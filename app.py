# ============================================================
# PART 1 â€” Importsã€åˆå§‹åŒ–ã€è³‡æ–™åº«ã€èªéŸ³ï¼ˆWhisper/TTSï¼‰ã€RAG
# ============================================================

import os
import json
import io
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
import librosa
import soundfile as sf

# è‡ªè¨‚æ¨¡çµ„
from resume_parser import parse_resume
from grader import grade_interview
from pdf_export import export_pdf
from html_export import export_html
from db import (
    init_db,
    save_candidate,
    save_interview,
    save_qa,
    save_scores,
    get_interviews,
    get_scores,
    get_qa,
)

# ====== åˆå§‹åŒ– ======
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("è«‹åœ¨ .env ä¸­è¨­å®š OPENAI_API_KEY")

client = OpenAI(api_key=api_key)

# ====== å­—å‹è¨­å®š ======
matplotlib.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]
matplotlib.rcParams["axes.unicode_minus"] = False

# ====== åˆå§‹åŒ–è³‡æ–™åº« ======
init_db()

# ============================================================
# ------------- èªéŸ³åŠŸèƒ½ï¼ˆWhisper + TTSï¼‰ ---------------------
# ============================================================

def speech_to_text(file):
    """
    Whisper èªéŸ³è¾¨è­˜ï¼ˆå›å‚³ Python dictï¼Œéœ€è¦ verbose_jsonï¼‰
    """
    resp = client.audio.transcriptions.create(
        model="whisper-1",
        file=file,
        response_format="verbose_json"
    )
    return resp.model_dump()   # â­ å›å‚³ dictï¼ˆä¸æ˜¯ Transcription ç‰©ä»¶ï¼‰


def synthesize_speech(text: str) -> bytes:
    """
    TTS â€” æ–‡å­—è½‰èªéŸ³
    """
    try:
        resp = client.audio.speech.create(
            model="gpt-4o-mini-tts",
            voice="alloy",
            input=text,
        )
        return resp.read()
    except Exception as e:
        st.error(f"TTS éŒ¯èª¤ï¼š{e}")
        return None


# ============================================================
# ----------- èªéŸ³ç‰¹å¾µåˆ†æï¼šWPM / Silence / Volume / Fillers ----
# ============================================================

FILLERS = ["å—¯", "å‘ƒ", "é‚£å€‹", "å°±æ˜¯", "like", "you know"]

def analyze_speech_features(whisper_resp, audio_bytes):
    """
    å›å‚³ dictï¼š
    {
      wpm,
      silence_ratio,
      volume_stability,
      filler_ratio
    }
    """

    result = {}

    # -------------------------
    # 1) èªé€Ÿï¼ˆWPMï¼‰
    # -------------------------
    total_words = len(whisper_resp["text"].split())
    segs = whisper_resp["segments"]
    total_time = segs[-1]["end"] - segs[0]["start"]
    wpm = (total_words / total_time) * 60 if total_time > 0 else 0
    result["wpm"] = round(wpm, 2)

    # -------------------------
    # 2) åœé “æ¯”ä¾‹
    # -------------------------
    silences = []
    for i in range(1, len(segs)):
        gap = segs[i]["start"] - segs[i-1]["end"]
        if gap > 0.25:
            silences.append(gap)

    total_silence = sum(silences)
    result["silence_ratio"] = round(total_silence / total_time, 3)

    # -------------------------
    # 3) éŸ³é‡ç©©å®šåº¦ï¼ˆVolume Stabilityï¼‰
    # -------------------------
    y, sr = sf.read(io.BytesIO(audio_bytes))
    frame_energy = librosa.feature.rms(y=y)[0]

    vol_mean = np.mean(frame_energy)
    vol_std = np.std(frame_energy)

    stability = 1 - (vol_std / (vol_mean + 1e-9))
    result["volume_stability"] = round(float(stability), 3)

    # -------------------------
    # 4) å¡«å……è©æ¯”ä¾‹
    # -------------------------
    filler_count = sum(whisper_resp["text"].count(f) for f in FILLERS)
    filler_ratio = filler_count / max(total_words, 1)
    result["filler_ratio"] = round(filler_ratio, 3)

    return result


# ============================================================
# ------------- RAG çŸ¥è­˜åº«è¼‰å…¥ï¼ˆé›»è³‡å­¸ç”Ÿå°ˆç”¨ï¼‰ ---------------
# ============================================================

class SimpleRAG:
    def __init__(self, folder="knowledge"):
        self.docs = []
        if not os.path.isdir(folder):
            return
        for fname in os.listdir(folder):
            if fname.endswith(".md"):
                with open(os.path.join(folder, fname), "r", encoding="utf-8") as f:
                    self.docs.append((fname, f.read()))

    def retrieve(self, job, query, top_k=3):
        if not self.docs:
            return []
        q = query.lower()
        scored = []
        for name, text in self.docs:
            score = sum(q.count(tok) for tok in q.split() if tok in text.lower())
            scored.append((score, text))
        scored.sort(reverse=True, key=lambda x: x[0])
        return [x[1] for x in scored[:top_k] if x[0] > 0]


@st.cache_resource
def load_rag():
    return SimpleRAG("knowledge")


rag = load_rag()

# ============================================================
# -------------------- UI & Session åˆå§‹åŒ– -------------------
# ============================================================

st.set_page_config(page_title="AI è™›æ“¬é¢è©¦å®˜", page_icon="ğŸ§‘â€ğŸ«")
st.title("ğŸ§‘â€ğŸ« AI é›»è³‡é ˜åŸŸè™›æ“¬é¢è©¦å®˜ï¼ˆèªéŸ³ + RAG + å±¥æ­· + è©•åˆ†ï¼‰")

def init_state(key, value):
    if key not in st.session_state:
        st.session_state[key] = value

init_state("messages", [])
init_state("started", False)
init_state("resume_info", None)
init_state("candidate_id", "")
init_state("qa_list", [])
init_state("last_question", None)
init_state("grade_result", None)
init_state("selected_history_interview_id", None)
init_state("voice_mode", False)
init_state("play_tts_first_question", False)
init_state("last_speech_features", None)

# ============================================================
# PART 2 â€” å±¥æ­·è§£æã€Prompt ç”Ÿæˆã€RAGã€LLM å›è¦†
# ============================================================

# ------------------------------------------------------------
# Sidebar è¨­ç½®
# ------------------------------------------------------------
with st.sidebar:
    st.header("é¢è©¦è¨­å®š")

    # å—è©¦è€… ID
    candidate_id = st.text_input("å—è©¦è€… IDï¼ˆå§“å / å­¸è™Ÿï¼‰", value=st.session_state.candidate_id)
    st.session_state.candidate_id = candidate_id

    if candidate_id:
        save_candidate(candidate_id)

    job_role = st.selectbox(
        "æ‡‰å¾µè·ç¼º",
        ["å¾Œç«¯å·¥ç¨‹å¸«", "AI å·¥ç¨‹å¸«", "è³‡æ–™å·¥ç¨‹å¸«", "å‰ç«¯å·¥ç¨‹å¸«"]
    )

    interview_style = st.selectbox(
        "é¢è©¦é¢¨æ ¼",
        ["æ™®é€š", "åš´æ ¼", "æº«å’Œ"]
    )

    st.markdown("---")
    st.subheader("å±¥æ­·ä¸Šå‚³ï¼ˆPDFï¼‰")
    uploaded_resume = st.file_uploader("é¸æ“‡ PDF å±¥æ­·", type=["pdf"])

    st.markdown("---")
    st.subheader("èªéŸ³æ¨¡å¼ï¼ˆTTS + Whisperï¼‰")
    st.session_state.voice_mode = st.checkbox("å•Ÿç”¨èªéŸ³æ¨¡å¼", value=False)

    st.markdown("---")
    st.subheader("æ­·å²ç´€éŒ„")

    history = []
    if candidate_id:
        history = get_interviews(candidate_id)

    if history:
        options = [
            f"{h['timestamp']}ï½œ{h['job_role']}ï½œID:{h['interview_id']}"
            for h in history
        ]
        picked = st.selectbox("é¸æ“‡ä¸€ç­†æ­·å²ç´€éŒ„ï¼š", options)
        idx = options.index(picked)
        st.session_state.selected_history_interview_id = history[idx]["interview_id"]
    else:
        st.caption("å°šç„¡æ­·å²ç´€éŒ„")

    st.markdown("---")
    if st.button("ğŸ” é‡ç½®é¢è©¦"):
        for key in [
            "messages", "started", "resume_info", "qa_list",
            "last_question", "grade_result", "last_speech_features"
        ]:
            st.session_state[key] = None if key == "resume_info" else []
        st.session_state.started = False
        st.rerun()


# ------------------------------------------------------------
# å±¥æ­·è§£æï¼ˆPDF â†’ JSONï¼‰
# ------------------------------------------------------------
if uploaded_resume and st.session_state.resume_info is None:
    with st.spinner("AI æ­£åœ¨è§£æä½ çš„å±¥æ­·â€¦"):
        st.session_state.resume_info = parse_resume(uploaded_resume)
    st.success("å±¥æ­·è§£æå®Œæˆï¼")

# å±•ç¤ºå±¥æ­·è§£æå…§å®¹
with st.expander("ğŸ“„ å±¥æ­·è§£æçµæœ"):
    ri = st.session_state.resume_info
    if ri:
        st.markdown("### ğŸ§© æŠ€èƒ½")
        st.write(", ".join(ri.get("skills", [])) or "ï¼ˆç„¡ï¼‰")

        st.markdown("### ğŸ“š å°ˆæ¡ˆ")
        for p in ri.get("projects", []):
            st.markdown(f"**{p['title']}** â€” {p['description']}")
            st.caption("æŠ€è¡“ï¼š" + ", ".join(p.get("tech_stack", [])))

        st.markdown("### ğŸ’¼ å·¥ä½œç¶“é©—")
        for w in ri.get("work_experience", []):
            st.markdown(f"**{w['company']} / {w['position']} ({w['duration']})**")
            st.write(w["description"])

        st.markdown("### ğŸ“ å­¸æ­·")
        for e in ri.get("education", []):
            st.markdown(f"- {e['school']} â€” {e['degree']} ({e['duration']})")

        st.markdown("### ğŸ“ è‡ªæˆ‘æ‘˜è¦")
        st.write(ri.get("summary", "ï¼ˆç„¡ï¼‰"))
    else:
        st.caption("å°šæœªä¸Šå‚³å±¥æ­·ã€‚")


# ------------------------------------------------------------
# Prompt å»ºæ§‹å™¨ï¼ˆå« RAGï¼‰
# ------------------------------------------------------------
def build_system_prompt(job, style, resume_info=None, rag_snippets=None):

    style_desc = {
        "æ™®é€š": "èªæ°£å°ˆæ¥­ï¼Œæå•è‡ªç„¶ã€‚",
        "åš´æ ¼": "èªæ°£ç›´æ¥ã€è¿½å•ç´°ç¯€ã€æœ‰å£“åŠ›æ„Ÿã€‚",
        "æº«å’Œ": "èªæ°£è¦ªåˆ‡ã€é¼“å‹µå¼æå•ã€‚",
    }[style]

    # ===== å±¥æ­·å…§å®¹ =====
    resume_context = ""
    if resume_info:
        skills = resume_info.get("skills", [])
        resume_context += f"å€™é¸äººæŠ€èƒ½ï¼š{', '.join(skills)}\n" if skills else ""

        if resume_info.get("projects"):
            resume_context += "å°ˆæ¡ˆï¼š\n"
            for p in resume_info["projects"]:
                resume_context += f"- {p['title']}: {p['description']}\n"

    # ===== RAG =====
    rag_context = ""
    if rag_snippets:
        rag_context += "\nä»¥ä¸‹ç‚ºè·ç¼ºç›¸é—œçš„æŠ€è¡“çŸ¥è­˜ç‰‡æ®µï¼ˆRAGï¼‰ï¼š\n"
        for i, sn in enumerate(rag_snippets, 1):
            rag_context += f"[{i}] {sn}\n"

    return f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ **{job}** é¢è©¦å®˜ã€‚

é¢è©¦é¢¨æ ¼ï¼š{style_desc}

è«‹éµå®ˆè¦å‰‡ï¼š
1. æ¯æ¬¡åªå•ä¸€é¡Œã€‚
2. å•é¡Œéœ€æœ‰æŠ€è¡“æ·±åº¦ï¼Œèšç„¦è·ç¼ºèƒ½åŠ›ã€‚
3. è‹¥å€™é¸äººç­”ä¸å®Œæ•´ï¼Œè¿½å•æ›´ç´°ã€‚
4. ç”¨ç¹é«”ä¸­æ–‡ã€‚

å€™é¸äººè³‡è¨Šï¼š
{resume_context}

æŠ€è¡“çŸ¥è­˜ï¼ˆRAGï¼‰ï¼š
{rag_context}

é–‹å§‹é¢è©¦ï¼Œè«‹æå‡ºç¬¬ä¸€é¡Œï¼šè‡ªæˆ‘ä»‹ç´¹ã€‚
""".strip()


# ------------------------------------------------------------
# LLM å›è¦†ï¼ˆå« RAG æŸ¥è©¢ï¼‰
# ------------------------------------------------------------
def call_llm(job, style, history, resume_info=None):

    # ---- RAG æŸ¥è©¢å­—ä¸² ----
    query_parts = [f"è·ç¼ºï¼š{job}"]

    last_q = None
    last_a = None

    for role, msg in reversed(history):
        if role == "assistant" and last_q is None:
            last_q = msg
        elif role == "user" and last_a is None:
            last_a = msg
        if last_q and last_a:
            break

    if last_q: query_parts.append("ä¸Šä¸€é¡Œï¼š" + last_q[:80])
    if last_a: query_parts.append("ä¸Šä¸€ç­”ï¼š" + last_a[:80])

    if resume_info and resume_info.get("skills"):
        query_parts.append("æŠ€èƒ½ï¼š" + ", ".join(resume_info["skills"]))

    rag_query = "ï¼›".join(query_parts)

    # ---- æ ¹æ“šè·ç¼ºè‡ªå‹•æ’åº RAG ----
    role_pref = {
        "å¾Œç«¯å·¥ç¨‹å¸«": ["algorithms", "datastructures", "system_design", "database"],
        "AI å·¥ç¨‹å¸«": ["ai_ml", "algorithms", "computer_arch"],
        "è³‡æ–™å·¥ç¨‹å¸«": ["database", "system_design"],
        "å‰ç«¯å·¥ç¨‹å¸«": ["algorithms", "system_design"],
    }.get(job, [])

    raw_snippets = rag.retrieve(job, rag_query, top_k=5)
    rag_snippets = sorted(
        raw_snippets,
        key=lambda x: any(tag in x.lower() for tag in role_pref),
        reverse=True
    )[:3]

    # ---- System prompt ----
    system_prompt = build_system_prompt(
        job,
        style,
        resume_info=resume_info,
        rag_snippets=rag_snippets
    )

    # ---- Messages ----
    messages = [{"role": "system", "content": system_prompt}]
    for role, content in history:
        messages.append({"role": role, "content": content})

    # ---- å‘¼å« OpenAI ----
    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=messages
    )
    return resp.choices[0].message.content


# ============================================================
# PART 3 â€” é¢è©¦æµç¨‹ï¼ˆé–‹å§‹é¢è©¦ + èªéŸ³å›ç­” + TTS + Whisperï¼‰
# ============================================================

# ------------------------------------------------------------
# é¡¯ç¤ºæ­·å²å°è©±è¨Šæ¯
# ------------------------------------------------------------
for role, content in st.session_state.messages:
    st.chat_message(role).markdown(content)


# ------------------------------------------------------------
# å°šæœªé–‹å§‹é¢è©¦
# ------------------------------------------------------------
if not st.session_state.started:

    if st.button("â–¶ï¸ é–‹å§‹é¢è©¦"):

        # ç”Ÿæˆç¬¬ä¸€é¡Œï¼ˆé€šå¸¸æ˜¯è‡ªæˆ‘ä»‹ç´¹ï¼‰
        first_reply = call_llm(
            job_role,
            interview_style,
            [],
            resume_info=st.session_state.resume_info
        )

        st.session_state.messages.append(("assistant", first_reply))
        st.session_state.last_question = first_reply
        st.session_state.started = True

        # â­ é—œéµï¼šç¬¬ä¸€é¡Œ TTS å¿…é ˆå»¶å¾Œä¸€è¼ªæ’­æ”¾
        if st.session_state.voice_mode:
            st.session_state.play_tts_first_question = True

        st.rerun()


# ------------------------------------------------------------
# ç¬¬ä¸€é¡Œ TTS æ’­æ”¾ï¼ˆé¿å…è¢« rerun åƒæ‰ï¼‰
# ------------------------------------------------------------
if st.session_state.get("play_tts_first_question", False):
    st.session_state.play_tts_first_question = False   # æ’­ä¸€æ¬¡å°±é—œæ‰

    text = st.session_state.last_question
    audio_bytes = synthesize_speech(text)
    if audio_bytes:
        st.audio(audio_bytes, format="audio/mp3")


# ------------------------------------------------------------
# é¢è©¦å·²ç¶“é–‹å§‹ â†’ ä½¿ç”¨è€…å›ç­”ï¼ˆèªéŸ³ / æ–‡å­—ï¼‰
# ------------------------------------------------------------
if st.session_state.started:

    st.markdown("### ğŸ§‘â€ğŸ’¬ è«‹å›ç­”ï¼š")

    # ============================================================
    # ğŸ¤ï¼ˆæ–¹å¼ 1ï¼‰ä½¿ç”¨è€…éŒ„éŸ³å›ç­”ï¼ˆStreamlit éŒ„éŸ³æŒ‰éˆ•ï¼‰
    # ============================================================
    st.markdown("#### ğŸ¤ èªéŸ³å›ç­”ï¼ˆéŒ„éŸ³ï¼‰")

    audio_rec = st.audio_input("é»æ“ŠéŒ„éŸ³ â†’ èªªå‡ºä½ çš„ç­”æ¡ˆ")

    voice_answer = None

    if audio_rec:
        with st.spinner("Whisper æ­£åœ¨è¾¨è­˜èªéŸ³â€¦"):
            whisper_resp = speech_to_text(audio_rec)

        voice_answer = whisper_resp["text"]

        # ===== èªéŸ³ç‰¹å¾µåˆ†æ =====
        speech_features = analyze_speech_features(whisper_resp, audio_rec.getvalue())
        st.session_state.last_speech_features = speech_features

        st.success("èªéŸ³è¾¨è­˜å®Œæˆï¼")

        st.markdown("### ğŸ§ èªéŸ³ç‰¹å¾µåˆ†æ")
        st.write(f"- èªé€Ÿï¼ˆWPMï¼‰ï¼š{speech_features['wpm']}")
        st.write(f"- åœé “æ¯”ä¾‹ï¼š{speech_features['silence_ratio']}")
        st.write(f"- éŸ³é‡ç©©å®šåº¦ï¼š{speech_features['volume_stability']}")
        st.write(f"- å¡«å……è©æ¯”ä¾‹ï¼š{speech_features['filler_ratio']}")

        st.markdown("---")

    # ============================================================
    # ğŸ¤ï¼ˆæ–¹å¼ 2ï¼‰ä½¿ç”¨è€…ä¸Šå‚³èªéŸ³æª”ï¼ˆå‚™ç”¨ï¼‰
    # ============================================================
    st.markdown("#### ğŸ“ èªéŸ³æª”ä¸Šå‚³å›ç­”ï¼ˆmp3 / wav / m4aï¼‰")
    audio_file = st.file_uploader("ä¸Šå‚³èªéŸ³æª”æ¡ˆ", type=["mp3", "wav", "m4a"])

    if audio_file and voice_answer is None:
        with st.spinner("Whisper æ­£åœ¨è¾¨è­˜èªéŸ³â€¦"):
            whisper_resp = speech_to_text(audio_file)

        voice_answer = whisper_resp["text"]

        speech_features = analyze_speech_features(whisper_resp, audio_file.read())
        st.session_state.last_speech_features = speech_features

        st.success("èªéŸ³è¾¨è­˜æˆåŠŸï¼")


    # ============================================================
    # ğŸ“ï¼ˆæ–¹å¼ 3ï¼‰æ–‡å­—å›ç­”
    # ============================================================
    st.markdown("#### âŒ¨ï¸ æ–‡å­—å›ç­”")
    text_answer = st.chat_input("è«‹è¼¸å…¥ä½ çš„å›ç­”â€¦")

    # èªéŸ³å„ªå…ˆæ–¼æ–‡å­—
    user_input = voice_answer if voice_answer else text_answer

    if user_input:

        # --------- è¨˜éŒ„ä¸Šä¸€é¡Œ+ä½¿ç”¨è€…å›ç­”ï¼ˆQAï¼‰ -----------
        st.session_state.qa_list.append({
            "question": st.session_state.last_question,
            "answer": user_input
        })

        st.session_state.messages.append(("user", user_input))
        st.chat_message("user").markdown(user_input)

        # --------- å‘¼å«é¢è©¦å®˜å–å¾—ä¸‹ä¸€é¡Œ ----------
        assistant_reply = call_llm(
            job_role,
            interview_style,
            st.session_state.messages,
            resume_info=st.session_state.resume_info,
        )

        st.session_state.messages.append(("assistant", assistant_reply))
        st.chat_message("assistant").markdown(assistant_reply)
        st.session_state.last_question = assistant_reply

        # --------- TTS æ’­æ”¾ä¸‹ä¸€é¡Œ ----------
        if st.session_state.voice_mode:
            tts_audio = synthesize_speech(assistant_reply)
            if tts_audio:
                st.audio(tts_audio, format="audio/mp3")

# ============================================================
# PART 4 â€” AI é¢è©¦è©•åˆ†ï¼ˆå«èªéŸ³ç‰¹å¾µ + èªéŸ³å»ºè­°ï¼‰
# ============================================================

# ------------------------------------------------------------
# è©•åˆ†æŒ‰éˆ•
# ------------------------------------------------------------
st.markdown("---")
st.subheader("ğŸ“Š é¢è©¦è©•åˆ†ï¼ˆAI åˆ†æï¼‰")

if st.button("ğŸ“Š çµæŸé¢è©¦ä¸¦é€²è¡Œ AI è©•åˆ†"):

    if not st.session_state.qa_list:
        st.warning("ä½ å°šæœªå›ç­”ä»»ä½•é¡Œç›®ï¼Œç„¡æ³•é€²è¡Œè©•åˆ†ã€‚")
    else:
        with st.spinner("AI æ­£åœ¨åˆ†æä½ çš„æ•´å ´é¢è©¦â€¦â€¦"):

            # â­ å‚³å…¥èªéŸ³ç‰¹å¾µè®“ grader åŠ æ¬Š
            result = grade_interview(
                st.session_state.qa_list,
                job_role,
                st.session_state.resume_info,
                speech_features=st.session_state.last_speech_features
            )

            st.session_state.grade_result = result

            # ----------- å„²å­˜åˆ°è³‡æ–™åº« -----------
            if st.session_state.candidate_id:

                interview_id = save_interview(
                    candidate_id=st.session_state.candidate_id,
                    job_role=job_role,
                    timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    summary=result["overall"]["summary"],
                )

                # å„²å­˜ QA
                for qa in st.session_state.qa_list:
                    save_qa(interview_id, qa["question"], qa["answer"])

                # å„²å­˜åˆ†æ•¸
                save_scores(interview_id, result["overall"])

        st.success("è©•åˆ†å®Œæˆï¼å‘ä¸‹æ²å‹•æŸ¥çœ‹åˆ†æçµæœã€‚")


# ------------------------------------------------------------
# é¡¯ç¤ºè©•åˆ†çµæœ
# ------------------------------------------------------------
if st.session_state.grade_result:

    result = st.session_state.grade_result
    overall = result["overall"]
    per_question = result["per_question"]

    # æ‹†åˆ†å…­å¤§é …ç›®
    tech = overall["technical"]
    comm = overall["communication"]
    struct = overall["structure"]
    rel = overall["relevance"]
    ps = overall["problem_solving"]
    gp = overall["growth_potential"]

    st.markdown("## â­ æ•´é«”è©•åˆ†")

    st.write(f"- æŠ€è¡“èƒ½åŠ›ï¼ˆTechnicalï¼‰ï¼š**{tech}/5**")
    st.write(f"- è¡¨é”èƒ½åŠ›ï¼ˆCommunicationï¼‰ï¼š**{comm}/5**")
    st.write(f"- å›ç­”çµæ§‹ï¼ˆStructureï¼‰ï¼š**{struct}/5**")
    st.write(f"- ç›¸é—œæ€§ï¼ˆRelevanceï¼‰ï¼š**{rel}/5**")
    st.write(f"- è§£é¡Œèƒ½åŠ›ï¼ˆProblem Solvingï¼‰ï¼š**{ps}/5**")
    st.write(f"- æˆé•·æ½›åŠ›ï¼ˆGrowth Potentialï¼‰ï¼š**{gp}/5**")

    st.markdown("### ğŸ“ æ•´é«”è©•è«–")
    st.write(overall["summary"])


    # ============================================================
    # ğŸ¤ èªéŸ³ç‰¹å¾µå€æ®µï¼ˆè‹¥æœ‰èªéŸ³å›ç­”ï¼‰
    # ============================================================
    st.markdown("## ğŸ¤ èªéŸ³è¡¨é”èƒ½åŠ›åˆ†æ")

    features = st.session_state.last_speech_features

    if features:
        st.write(f"- èªé€Ÿï¼ˆWPMï¼‰ï¼š**{features['wpm']}**")
        st.write(f"- åœé “æ¯”ä¾‹ï¼š**{features['silence_ratio']}**")
        st.write(f"- éŸ³é‡ç©©å®šåº¦ï¼š**{features['volume_stability']}**")
        st.write(f"- å¡«å……è©æ¯”ä¾‹ï¼š**{features['filler_ratio']}**")
    else:
        st.caption("ï¼ˆæœ¬æ¬¡æ²’æœ‰èªéŸ³å›ç­”ï¼Œå› æ­¤ç„¡æ³•é€²è¡ŒèªéŸ³åˆ†æã€‚ï¼‰")


    # ============================================================
    # ğŸ¤ AI èªéŸ³è¡¨é”æ”¹å–„å»ºè­°ï¼ˆDï¼‰
    # ============================================================
    from grader import generate_speech_feedback

    st.markdown("## ğŸ§ èªéŸ³æ”¹å–„å»ºè­°ï¼ˆAI ç”Ÿæˆï¼‰")

    speech_fb = generate_speech_feedback(features)
    st.write(speech_fb)


# ============================================================
# PART 5 â€” é›·é”åœ– + æ­·å²æ¯”è¼ƒ + é€é¡Œå›é¥‹
# ============================================================

if st.session_state.grade_result:

    result = st.session_state.grade_result
    overall = result["overall"]
    per_question = result["per_question"]

    # å„é …åˆ†æ•¸
    tech = overall["technical"]
    comm = overall["communication"]
    struct = overall["structure"]
    rel = overall["relevance"]
    ps = overall["problem_solving"]
    gp = overall["growth_potential"]

    # ============================================================
    # ğŸ“ˆ é›·é”åœ–ï¼ˆæœ¬æ¬¡é¢è©¦ï¼‰
    # ============================================================
    st.markdown("## ğŸ“Š æœ¬æ¬¡é¢è©¦é›·é”åœ–")

    categories = ["technical", "communication", "structure",
                  "relevance", "problem_solving", "growth_potential"]
    labels_zh = ["æŠ€è¡“", "è¡¨é”", "çµæ§‹", "ç›¸é—œæ€§", "è§£é¡Œ", "æ½›åŠ›"]

    scores = [tech, comm, struct, rel, ps, gp]
    values = scores + scores[:1]
    angles = np.linspace(0, 2*np.pi, len(categories) + 1)

    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw={"polar": True})
    ax.plot(angles, values, linewidth=2)
    ax.fill(angles, values, alpha=0.25)
    ax.set_thetagrids(angles[:-1] * 180/np.pi, labels_zh)
    ax.set_ylim(0, 5)
    ax.set_yticks([1, 2, 3, 4, 5])
    plt.tight_layout()
    st.pyplot(fig)

    # ============================================================
    # ğŸ”„ æ­·å²æ¯”è¼ƒé›·é”åœ–
    # ============================================================
    if st.session_state.selected_history_interview_id:

        st.markdown("## ğŸ”„ èˆ‡æ­·å²é¢è©¦æ¯”è¼ƒ")

        ref_scores = get_scores(st.session_state.selected_history_interview_id)

        if ref_scores:

            ref_vals = [
                ref_scores["technical"],
                ref_scores["communication"],
                ref_scores["structure"],
                ref_scores["relevance"],
                ref_scores["problem_solving"],
                ref_scores["growth_potential"],
            ]
            cur_vals = scores
            ref_plot = ref_vals + ref_vals[:1]
            cur_plot = cur_vals + cur_vals[:1]

            fig2, ax2 = plt.subplots(figsize=(6, 6), subplot_kw={"polar": True})
            ax2.plot(angles, ref_plot, "r--", linewidth=1.8, label="æ­·å²ç´€éŒ„")
            ax2.plot(angles, cur_plot, "b-", linewidth=2.2, label="æœ¬æ¬¡é¢è©¦")
            ax2.fill(angles, cur_plot, alpha=0.25)

            ax2.set_thetagrids(angles[:-1] * 180/np.pi, labels_zh)
            ax2.set_ylim(0, 5)
            ax2.legend(loc="upper right", bbox_to_anchor=(1.25, 1.12))
            plt.tight_layout()

            st.pyplot(fig2)
            st.caption("æç¤ºï¼šè™›ç·šä»£è¡¨æ­·å²ç´€éŒ„ï¼Œå¯¦ç·šä»£è¡¨æœ¬æ¬¡é¢è©¦ã€‚")

    # ============================================================
    # ğŸ“ é€é¡Œå›é¥‹ï¼ˆQuestion-by-Questionï¼‰
    # ============================================================
    st.markdown("## ğŸ“ é€é¡Œå›é¥‹ï¼ˆAI åˆ†æï¼‰")

    for i, item in enumerate(per_question, 1):

        s = item["score"]

        st.markdown(f"### ç¬¬ {i} é¡Œ")
        st.markdown(f"**é¡Œç›®ï¼š** {item['question']}")
        st.markdown(f"**ä½ çš„å›ç­”ï¼š** {item['answer']}")

        st.write(
            f"- æŠ€è¡“ï¼š{s['technical']}/5 ï½œ "
            f"è¡¨é”ï¼š{s['communication']}/5 ï½œ "
            f"çµæ§‹ï¼š{s['structure']}/5 ï½œ "
            f"ç›¸é—œæ€§ï¼š{s['relevance']}/5 ï½œ "
            f"è§£é¡Œï¼š{s['problem_solving']}/5 ï½œ "
            f"æ½›åŠ›ï¼š{s['growth_potential']}/5"
        )

        st.markdown(f"**AI å›é¥‹ï¼š** {item['feedback']}")
        st.markdown("---")

# ============================================================
# PART 6 â€” é¢è©¦å ±å‘Šä¸‹è¼‰ï¼ˆMarkdown / PDF / HTMLï¼‰
# ============================================================

if st.session_state.grade_result:

    result = st.session_state.grade_result
    overall = result["overall"]
    per_question = result["per_question"]

    tech = overall["technical"]
    comm = overall["communication"]
    struct = overall["structure"]
    rel = overall["relevance"]
    ps = overall["problem_solving"]
    gp = overall["growth_potential"]

    sf = st.session_state.last_speech_features
    from grader import generate_speech_feedback

    st.markdown("## ğŸ’¾ ä¸‹è¼‰æœ¬æ¬¡é¢è©¦å ±å‘Š")

    # ------------------ å»ºç«‹ Markdown å…§å®¹ ------------------
    def build_report_md():
        lines = []
        lines.append("# AI è™›æ“¬é¢è©¦å®˜é¢è©¦å ±å‘Š\n")
        lines.append(f"- å—è©¦è€…ï¼š{st.session_state.candidate_id}")
        lines.append(f"- æ‡‰å¾µè·ç¼ºï¼š{job_role}")
        lines.append(f"- æ—¥æœŸï¼š{datetime.now().strftime('%Y-%m-%d')}\n")

        # æ•´é«”è©•åˆ†
        lines.append("## æ•´é«”è©•åˆ†")
        lines.append(f"- æŠ€è¡“èƒ½åŠ›ï¼ˆTechnicalï¼‰ï¼š{tech}/5")
        lines.append(f"- è¡¨é”èƒ½åŠ›ï¼ˆCommunicationï¼‰ï¼š{comm}/5")
        lines.append(f"- å›ç­”çµæ§‹ï¼ˆStructureï¼‰ï¼š{struct}/5")
        lines.append(f"- ç›¸é—œæ€§ï¼ˆRelevanceï¼‰ï¼š{rel}/5")
        lines.append(f"- è§£é¡Œèƒ½åŠ›ï¼ˆProblem Solvingï¼‰ï¼š{ps}/5")
        lines.append(f"- æˆé•·æ½›åŠ›ï¼ˆGrowth Potentialï¼‰ï¼š{gp}/5\n")

        # æ•´é«”è©•è«–
        lines.append("## æ•´é«”è©•è«–")
        lines.append(overall["summary"] + "\n")

        # èªéŸ³åˆ†æï¼ˆå¦‚æœæœ‰ï¼‰
        if sf:
            lines.append("## èªéŸ³è¡¨é”åˆ†æ")
            lines.append(f"- èªé€Ÿï¼ˆWPMï¼‰ï¼š{sf['wpm']}")
            lines.append(f"- åœé “æ¯”ä¾‹ï¼š{sf['silence_ratio']}")
            lines.append(f"- éŸ³é‡ç©©å®šåº¦ï¼š{sf['volume_stability']}")
            lines.append(f"- å¡«å……è©æ¯”ä¾‹ï¼š{sf['filler_ratio']}\n")

            lines.append("## èªéŸ³æ”¹å–„å»ºè­°ï¼ˆAIï¼‰")
            lines.append(generate_speech_feedback(sf) + "\n")
        else:
            lines.append("## èªéŸ³è¡¨é”åˆ†æ")
            lines.append("æœ¬æ¬¡æœªæä¾›èªéŸ³å›ç­”ï¼Œå› æ­¤ç„¡èªéŸ³åˆ†æèˆ‡å»ºè­°ã€‚\n")

        # é€é¡Œå›é¥‹
        lines.append("## é€é¡Œå›é¥‹ï¼ˆQuestion-by-Questionï¼‰")
        for i, item in enumerate(per_question, 1):
            s = item["score"]
            lines.append(f"### ç¬¬ {i} é¡Œ")
            lines.append(f"- é¡Œç›®ï¼š{item['question']}")
            lines.append(f"- å›ç­”ï¼š{item['answer']}")
            lines.append(
                f"- åˆ†æ•¸ï¼šæŠ€è¡“ {s['technical']}/5ï¼Œ"
                f"è¡¨é” {s['communication']}/5ï¼Œ"
                f"çµæ§‹ {s['structure']}/5ï¼Œ"
                f"ç›¸é—œæ€§ {s['relevance']}/5ï¼Œ"
                f"è§£é¡Œ {s['problem_solving']}/5ï¼Œ"
                f"æ½›åŠ› {s['growth_potential']}/5"
            )
            lines.append(f"- AI å›é¥‹ï¼š{item['feedback']}\n")

        return "\n".join(lines)

    report_md = build_report_md()

    # ------------------ Markdown ä¸‹è¼‰ ------------------
    st.download_button(
        "ğŸ“˜ ä¸‹è¼‰ Markdown å ±å‘Š",
        data=report_md,
        file_name="interview_report.md",
        mime="text/markdown",
    )

    # ------------------ PDF ä¸‹è¼‰ ------------------
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        export_pdf(tmp.name, report_md)
        with open(tmp.name, "rb") as f:
            pdf_bytes = f.read()

    st.download_button(
        "ğŸ“„ ä¸‹è¼‰ PDF å ±å‘Š",
        data=pdf_bytes,
        file_name="interview_report.pdf",
        mime="application/pdf",
    )

    # ------------------ HTML ä¸‹è¼‰ ------------------
    html_content = export_html(report_md)
    st.download_button(
        "ğŸŒ ä¸‹è¼‰ HTML å ±å‘Š",
        data=html_content,
        file_name="interview_report.html",
        mime="text/html",
    )
