import os
import json
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
import io
import tempfile

# è‡ªè¨‚æ¨¡çµ„
from resume_parser import parse_resume
from grader import grade_interview, generate_suggestions
from pdf_export import export_pdf
from html_export import export_html
from voice_analysis import analyze_voice
from db import (
    init_db,
    save_candidate,
    save_interview,
    save_qa,
    save_scores,
    get_interviews,
    get_scores,
    get_qa
)

# ====== åˆå§‹åŒ–èˆ‡è¨­å®š ======
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("è«‹åœ¨ .env è¨­å®š OPENAI_API_KEY")
    st.stop()

client = OpenAI(api_key=api_key)

# å­—å‹
# æ³¨æ„ï¼šé€™å€‹å­—å‹è·¯å¾‘åœ¨é Windows ç³»çµ±ä¸Šæœƒå‡ºéŒ¯ï¼Œéƒ¨ç½²æ™‚éœ€è¦æ›´æ›
try:
    matplotlib.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]
    matplotlib.rcParams["axes.unicode_minus"] = False
except Exception as e:
    print(f"ç„¡æ³•è¨­å®š Matplotlib å­—å‹: {e}")


# åˆå§‹åŒ–è³‡æ–™åº«
init_db()

# ====== èªéŸ³åŠŸèƒ½ ======
def synthesize_speech(text: str) -> bytes:
    try:
        resp = client.audio.speech.create(
            model="gpt-4o-mini-tts",
            voice="alloy",
            input=text,
            response_format="opus",
        )
        return resp.read()
    except Exception as e:
        st.error(f"TTS éŒ¯èª¤ï¼š{e}")
        return None

def speech_to_text(file) -> str:
    try:
        resp = client.audio.transcriptions.create(
            model="whisper-1",
            file=file,
        )
        return resp.text
    except Exception as e:
        st.error(f"Whisper éŒ¯èª¤ï¼š{e}")
        return ""

# ====== RAG ======
@st.cache_resource
def get_rag():
    class SimpleRAG:
        def __init__(self, folder="knowledge"):
            self.docs = []
            if not os.path.isdir(folder):
                return
            for fname in os.listdir(folder):
                if fname.endswith(".md"):
                    with open(os.path.join(folder, fname), "r", encoding="utf-8") as f:
                        self.docs.append((fname, f.read()))

        def retrieve(self, job: str, query: str, top_k=3):
            if not self.docs:
                return []
            q = query.lower()
            scored = []
            for name, text in self.docs:
                score = sum(q.count(tok) for tok in q.split() if tok in text.lower())
                scored.append((score, name, text))
            scored.sort(reverse=True, key=lambda x: x[0])
            return [x[2] for x in scored[:top_k] if x[0] > 0]
    return SimpleRAG("knowledge")

rag = get_rag()

# ====== Streamlit UI ======
st.set_page_config(page_title="AI è™›æ“¬é¢è©¦å®˜", page_icon="ğŸ§‘â€ğŸ«")
st.title("ğŸ§‘â€ğŸ« AI è™›æ“¬é¢è©¦å®˜")
st.caption("å±¥æ­· + RAG + èªéŸ³ + æ­·å²ç´€éŒ„ + å€‹äººåŒ–å»ºè­°")


# ====== Session State ======
def init_state(k, v):
    if k not in st.session_state:
        st.session_state[k] = v

init_state("messages", [])
init_state("started", False)
init_state("resume_info", None)
init_state("candidate_id", "")
init_state("qa_list", [])
init_state("last_question", None)
init_state("grade_result", None)
init_state("selected_history_interview_id", None)
init_state("voice_mode", False)
init_state("voice_analysis_results", [])
init_state("suggestions", None)
init_state("last_processed_input", None)

# ====== Sidebar ======
with st.sidebar:
    st.header("é¢è©¦è¨­å®š")

    candidate_id = st.text_input(
        "å—è©¦è€… IDï¼ˆå§“å / å­¸è™Ÿï¼‰",
        value=st.session_state.candidate_id,
        key="candidate_id_input"
    )
    st.session_state.candidate_id = candidate_id

    if candidate_id:
        save_candidate(candidate_id)

    job_role = st.selectbox(
        "æ‡‰å¾µè·ç¼º",
        ["å¾Œç«¯å·¥ç¨‹å¸«", "AI å·¥ç¨‹å¸«", "è³‡æ–™å·¥ç¨‹å¸«", "å‰ç«¯å·¥ç¨‹å¸«"],
        key="job_role_input"
    )

    interview_style = st.selectbox(
        "é¢è©¦é¢¨æ ¼", ["æ™®é€š", "åš´æ ¼", "æº«å’Œ"],
        key="interview_style_input"
    )

    st.markdown("---")
    st.subheader("ä¸Šå‚³å±¥æ­·ï¼ˆPDFï¼‰")
    uploaded_resume = st.file_uploader("PDF å±¥æ­·", type=["pdf"], key="resume_uploader")

    st.markdown("---")
    st.subheader("èªéŸ³æ¨¡å¼")
    st.session_state.voice_mode = st.checkbox("å•Ÿç”¨èªéŸ³ï¼ˆTTS + Whisperï¼‰", value=st.session_state.voice_mode, key="voice_mode_checkbox")

    st.markdown("---")
    st.subheader("æ­·å²ç´€éŒ„")
    if candidate_id:
        history_list = get_interviews(candidate_id)
        if history_list:
            labels = [f"{h['timestamp']}ï½œ{h['job_role']}" for h in history_list]
            
            # Find the index of the selected interview
            default_idx = 0
            if st.session_state.selected_history_interview_id:
                for i, h in enumerate(history_list):
                    if h["interview_id"] == st.session_state.selected_history_interview_id:
                        default_idx = i
                        break
            
            picked_label = st.selectbox("é¸æ“‡ç´€éŒ„ï¼š", labels, index=default_idx, key="history_selectbox")
            # Find the id from the picked label
            for h in history_list:
                if f"{h['timestamp']}ï½œ{h['job_role']}" == picked_label:
                    st.session_state.selected_history_interview_id = h["interview_id"]
                    break
        else:
            st.caption("æ­¤å—è©¦è€…ç›®å‰æ²’æœ‰æ­·å²è³‡æ–™")
    else:
        st.caption("è«‹è¼¸å…¥å—è©¦è€… ID æ‰èƒ½æŸ¥è©¢æ­·å²ç´€éŒ„")

    st.markdown("---")
    reset_btn = st.button("ğŸ” é‡ç½®æœ¬æ¬¡é¢è©¦")

# --------------------------------------------------------
# é‡ç½®ç‹€æ…‹
# --------------------------------------------------------
if reset_btn:
    st.session_state.messages = []
    st.session_state.started = False
    st.session_state.resume_info = None
    st.session_state.qa_list = []
    st.session_state.last_question = None
    st.session_state.grade_result = None
    st.session_state.selected_history_interview_id = None
    st.session_state.voice_analysis_results = []
    st.session_state.suggestions = None
    st.session_state.last_processed_input = None
    st.rerun()

# --------------------------------------------------------
# å±¥æ­·è§£æï¼ˆPDF â†’ JSONï¼‰
# --------------------------------------------------------
if uploaded_resume and st.session_state.resume_info is None:
    with st.spinner("AI æ­£åœ¨è§£æå±¥æ­·â€¦"):
        st.session_state.resume_info = parse_resume(uploaded_resume)
    st.success("å±¥æ­·è§£æå®Œæˆï¼")

# å±•é–‹å±¥æ­·æ‘˜è¦
with st.expander("ğŸ“„ å±¥æ­·è§£æçµæœ"):
    ri = st.session_state.resume_info
    if ri:
        st.markdown("### ğŸ§© æŠ€èƒ½")
        st.write(", ".join(ri.get("skills", [])) or "ï¼ˆç„¡ï¼‰")
        st.markdown("### ğŸ“š å°ˆæ¡ˆ")
        for p in ri.get("projects", []):
            st.markdown(f"**{p['title']}** â€” {p['description']}")
            st.write("æŠ€è¡“ï¼š", ", ".join(p.get("tech_stack", [])))
        st.markdown("### ğŸ’¼ å·¥ä½œç¶“é©—")
        for w in ri.get("work_experience", []):
            st.markdown(f"**{w['company']} / {w['position']} ({w['duration']})**")
            st.write(w["description"])
        st.markdown("### ğŸ“ å­¸æ­·")
        for e in ri.get("education", []):
            st.markdown(f"{e['school']} â€” {e['degree']} ({e['duration']})")
        st.markdown("### ğŸ“ è‡ªæˆ‘æ‘˜è¦")
        st.write(ri.get("summary", "ï¼ˆç„¡ï¼‰"))
    else:
        st.caption("å°šæœªä¸Šå‚³å±¥æ­·ã€‚ à¦¸à¦¨")

# --------------------------------------------------------
# Prompt çµ„åˆå™¨
# --------------------------------------------------------
def build_system_prompt(job: str, style: str, resume_info=None, rag_snippets=None):
    style_map = {"æ™®é€š": "èªæ°£å°ˆæ¥­ã€æ­£å¸¸é¢è©¦æµç¨‹ã€‚", "åš´æ ¼": "èªæ°£ç›´æ¥ã€æœ‰å£“åŠ›ã€æ·±åº¦è¿½å•ã€‚", "æº«å’Œ": "èªæ°£å‹å–„ã€è¬›è§£å¼ã€é¼“å‹µå­¸ç”Ÿã€‚"}
    style_desc = style_map[style]
    resume_context = ""
    if resume_info:
        skills = ", ".join(resume_info.get("skills", []))
        resume_context += f"å€™é¸äººæŠ€èƒ½ï¼š{skills or 'ï¼ˆç„¡ï¼‰'}\n"
        if resume_info.get("projects"):
            resume_context += "å°ˆæ¡ˆç¶“é©—ï¼š\n"
            for p in resume_info["projects"]:
                resume_context += f"- {p['title']}: {p['description']}\n"
        summary = resume_info.get("summary", "")
        if summary:
            resume_context += f"è‡ªæˆ‘ä»‹ç´¹æ‘˜è¦ï¼š{summary}\n"
    rag_context = ""
    if rag_snippets:
        rag_context += "\nä»¥ä¸‹ç‚ºèˆ‡è·ç¼ºç›¸é—œçš„é‡è¦æŠ€è¡“çŸ¥è­˜ç‰‡æ®µï¼ˆRAGï¼‰ï¼š\n"
        for i, snip in enumerate(rag_snippets, start=1):
            rag_context += f"[ç‰‡æ®µ {i}]\n{snip}\n\n"
    return f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­ã€Œ{job}ã€é ˜åŸŸçš„é¢è©¦å®˜ã€‚
**ä½ çš„æœ€é‡è¦è¦å‰‡æ˜¯ï¼šæ¯æ¬¡åªå•ä¸€å€‹å•é¡Œã€‚** ä½ çš„å›è¦†å…§å®¹å¿…é ˆåªèƒ½åŒ…å«ä¸€å€‹å•é¡Œï¼Œä¸èƒ½åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—æˆ–ç¬¬äºŒå€‹å•é¡Œã€‚å¦‚æœé•åæ­¤è¦å‰‡ï¼Œæ•´å€‹ç³»çµ±å°‡æœƒå¤±æ•—ã€‚

è«‹åš´æ ¼éµå®ˆä»¥ä¸‹æ‰€æœ‰åŸå‰‡ï¼š
1. **ä½¿ç”¨è€…è¦æ±‚çµæŸï¼š** å¦‚æœå€™é¸äººæ˜ç¢ºè¡¨ç¤ºæƒ³çµæŸé¢è©¦ï¼ˆä¾‹å¦‚èªªå‡ºã€Œæˆ‘ä¸æƒ³å›ç­”äº†ã€ã€ã€ŒçµæŸé¢è©¦ã€ç­‰ï¼‰ï¼Œä½ å¿…é ˆç«‹åˆ»åœæ­¢æå•ï¼Œä¸¦ç›´æ¥å›å‚³ `[END_INTERVIEW]` æŒ‡ä»¤ã€‚
2. **è‡ªå‹•çµæŸé¢è©¦**ï¼šç•¶ä½ åˆ¤æ–·é¢è©¦æ‡‰çµæŸæ™‚ï¼ˆæ ¸å¿ƒå•é¡Œå•å®Œã€æŒçºŒç­”éæ‰€å•ã€æˆ–è¡¨ç¾éå·®ï¼‰ï¼Œä¹ŸåŒæ¨£å›å‚³ `[END_INTERVIEW]` æŒ‡ä»¤ã€‚
3. ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
4. è‹¥å€™é¸äººå›ç­”ä¸å®Œæ•´ï¼Œé©åº¦è¿½å•æŠ€è¡“ç´°ç¯€ã€‚
5. é¢¨æ ¼ï¼š{style_desc}
6. é¡Œç›®æ·±åº¦æ¯”ä¸€èˆ¬é¢è©¦æ›´åå·¥ç¨‹å¯¦ä½œã€æŠ€è¡“ç†è§£ã€‚

æ ¹æ“šä»¥ä¸‹å€™é¸äººè³‡è¨Šèˆ‡èƒŒæ™¯ï¼š
{resume_context}

{rag_context}

è«‹é–‹å§‹é¢è©¦ï¼Œç¬¬ä¸€é¡Œè«‹å°æ–¹è‡ªæˆ‘ä»‹ç´¹ã€‚
""".strip()

# --------------------------------------------------------
# LLM ä¸»å›è¦† function
# --------------------------------------------------------
def call_llm(job: str, style: str, history, resume_info=None):
    query_parts = [f"è·ç¼ºï¼š{job}"]

    last_q, last_a = None, None
    for role, msg in reversed(history):
        if role == "assistant" and last_q is None: last_q = msg
        elif role == "user" and last_a is None: last_a = msg
        if last_q and last_a: break

    if last_q: query_parts.append("ä¸Šä¸€é¡Œï¼š" + last_q[:100])
    if last_a: query_parts.append("ä¸Šä¸€ç­”ï¼š" + last_a[:100])

    if resume_info:
        skills = resume_info.get("skills", [])
        if skills: query_parts.append("æŠ€èƒ½ï¼š" + ", ".join(skills))

    rag_query = "ï¼›".join(query_parts)

    role_map = {"å¾Œç«¯å·¥ç¨‹å¸«": ["algorithms", "datastructures", "system_design", "database"], "AI å·¥ç¨‹å¸«": ["ai_ml", "algorithms", "computer_arch"], "è³‡æ–™å·¥ç¨‹å¸«": ["database", "system_design"], "å‰ç«¯å·¥ç¨‹å¸«": ["algorithms", "system_design"]}
    preferred_tags = role_map.get(job, [])

    raw_snips = rag.retrieve(job, rag_query, top_k=5)
    rag_snippets = sorted(raw_snips, key=lambda x: any(tag in x.lower() for tag in preferred_tags), reverse=True)[:3]

    system_prompt = build_system_prompt(
        job,
        style,
        resume_info=resume_info,
        rag_snippets=rag_snippets,
    )

    msgs = [{"role": "system", "content": system_prompt}] + [{"role": r, "content": c} for r, c in history]

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=msgs,
    )
    return resp.choices[0].message.content

# --------------------------------------------------------
# è©•åˆ†èˆ‡å»ºè­°ç”¢ç”Ÿå‡½å¼
# --------------------------------------------------------
def run_grading():
    if not st.session_state.qa_list:
        st.warning("å°šæœªå›ç­”ä»»ä½•é¡Œç›®ï¼Œç„¡æ³•è©•åˆ†ã€‚ à¦¸à¦¨")
        return
    with st.spinner("AI æ­£åœ¨åˆ†æä½ çš„æ•´å ´é¢è©¦â€¦"):
        result = grade_interview(st.session_state.qa_list, job_role, st.session_state.resume_info)
        st.session_state.grade_result = result
        if st.session_state.candidate_id:
            interview_id = save_interview(candidate_id=st.session_state.candidate_id, job_role=job_role, timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"), summary=result["overall"].get("summary", ""))
            for qa in st.session_state.qa_list:
                save_qa(interview_id, qa["question"], qa["answer"])
            save_scores(interview_id, result["overall"])
    with st.spinner("AI æ­£åœ¨ç”¢ç”Ÿå€‹äººåŒ–å»ºè­°â€¦"):
        suggestions = generate_suggestions(st.session_state.qa_list, st.session_state.grade_result["overall"])
        st.session_state.suggestions = suggestions
    st.success("è©•åˆ†èˆ‡å»ºè­°çš†å·²å®Œæˆï¼è«‹å‘ä¸‹æŸ¥çœ‹çµæœã€‚ à¦¸à¦¨")

# --------------------------------------------------------
# ä¸»æµç¨‹
# --------------------------------------------------------
for role, content in st.session_state.messages:
    st.chat_message(role).markdown(content)

if not st.session_state.started:
    if st.button("â–¶ï¸ é–‹å§‹é¢è©¦"):
        first_reply = call_llm(
            job_role,
            interview_style,
            [],
            resume_info=st.session_state.resume_info,
        )
        st.session_state.messages.append(("assistant", first_reply))
        st.session_state.last_question = first_reply
        st.session_state.started = True
        if st.session_state.voice_mode:
            audio_bytes = synthesize_speech(first_reply)
            if audio_bytes:
                st.session_state.tts_audio_bytes = audio_bytes
        st.rerun()
else:
    if "tts_audio_bytes" in st.session_state and st.session_state.tts_audio_bytes:
        st.audio(st.session_state.tts_audio_bytes, format="audio/opus")
        st.session_state.tts_audio_bytes = None

    if not st.session_state.grade_result:
        st.markdown("### å›ç­”æœ¬é¡Œ")
        audio_rec = st.audio_input("ğŸ¤ æŒ‰ä¸‹é–‹å§‹éŒ„éŸ³ â†’ å°è‘—éº¥å…‹é¢¨å›ç­”")
        voice_answer = None
        if audio_rec:
            with st.spinner("Whisper æ­£åœ¨è¾¨è­˜ä½ çš„èªéŸ³â€¦"):
                voice_answer = speech_to_text(audio_rec)
            if voice_answer:
                st.success("èªéŸ³è¾¨è­˜æˆåŠŸï¼ à¦¸à¦¨")
                st.write("ä½ çš„èªéŸ³å…§å®¹ï¼š", voice_answer)
        
        audio_file = st.file_uploader("ï¼ˆå¯é¸ï¼‰ä¸Šå‚³èªéŸ³æª” mp3/wav/m4a", type=["mp3","wav","m4a"])
        if audio_file and not voice_answer:
            with st.spinner("Whisper æ­£åœ¨è¾¨è­˜ä½ çš„èªéŸ³â€¦"):
                voice_answer = speech_to_text(audio_file)
            if voice_answer:
                st.success("èªéŸ³è¾¨è­˜æˆåŠŸï¼ à¦¸à¦¨")
                st.write("ä½ çš„èªéŸ³å…§å®¹ï¼š", voice_answer)

        text_answer = st.chat_input("è«‹è¼¸å…¥ä½ çš„å›ç­”â€¦")
        user_input = voice_answer if voice_answer else text_answer

        if user_input and user_input != st.session_state.last_processed_input:
            st.session_state.last_processed_input = user_input
            source_audio = audio_rec if audio_rec else audio_file
            if source_audio and user_input == voice_answer:
                with st.spinner("æ­£åœ¨åˆ†æä½ çš„èªéŸ³ç‰¹å¾µâ€¦"):
                    analysis_result = analyze_voice(source_audio)
                    st.session_state.voice_analysis_results.append(analysis_result)
            else:
                st.session_state.voice_analysis_results.append(None)

            if st.session_state.last_question:
                st.session_state.qa_list.append({"question": st.session_state.last_question, "answer": user_input})
            
            st.session_state.messages.append(("user", user_input))
            
            with st.chat_message("user"):
                st.markdown(user_input)

            with st.spinner("AI é¢è©¦å®˜æ­£åœ¨æ€è€ƒä¸‹ä¸€é¡Œ..."):
                assistant_reply = call_llm(
                    job_role,
                    interview_style,
                    st.session_state.messages,
                    resume_info=st.session_state.resume_info,
                )

            if "[END_INTERVIEW]" in assistant_reply:
                st.info("å¥½çš„ï¼Œä»Šå¤©çš„é¢è©¦å·®ä¸å¤šåˆ°æ­¤çµæŸã€‚æˆ‘å€‘å°‡é–‹å§‹ç‚ºæ‚¨è©•åˆ†ã€‚ à¦¸à¦¨")
                run_grading()
                st.rerun()
            else:
                questions = [q.strip() for q in assistant_reply.split('\n') if q.strip()]
                first_question = questions[0] if questions else "æŠ±æ­‰ï¼Œæˆ‘å¥½åƒæ²’æœ‰æƒ³åˆ°å•é¡Œï¼Œå¯ä»¥è«‹æ‚¨å†èªªä¸€æ¬¡å—ï¼Ÿ"
                
                st.session_state.messages.append(("assistant", first_question))
                with st.chat_message("assistant"):
                    st.markdown(first_question)
                st.session_state.last_question = first_question

                if st.session_state.voice_mode:
                    tts_audio = synthesize_speech(first_question)
                    if tts_audio:
                        st.audio(tts_audio, format="audio/opus")
                # No rerun here to wait for next user input
        
        st.markdown("---")
        st.subheader("ğŸ“Š é¢è©¦è©•åˆ†")
        if st.button("ğŸ“Š çµæŸé¢è©¦ä¸¦é€²è¡Œ AI è©•åˆ†"):
            run_grading()
            st.rerun()

if st.session_state.grade_result:
    result = st.session_state.grade_result
    overall = result["overall"]
    per_question = result["per_question"]
    tech, comm, struct, rel, ps, gp = (overall.get(k, 0) for k in ["technical", "communication", "structure", "relevance", "problem_solving", "growth_potential"])

    st.markdown("### â­ æ•´é«”è©•åˆ†")
    st.write(f"- æŠ€è¡“ï¼ˆtechnicalï¼‰ï¼š**{tech} / 5**")
    st.write(f"- è¡¨é”ï¼ˆcommunicationï¼‰ï¼š**{comm} / 5**")
    st.write(f"- çµæ§‹ï¼ˆstructureï¼‰ï¼š**{struct} / 5**")
    st.write(f"- ç›¸é—œæ€§ï¼ˆrelevanceï¼‰ï¼š**{rel} / 5**")
    st.write(f"- è§£é¡Œèƒ½åŠ›ï¼ˆproblem_solvingï¼‰ï¼š**{ps} / 5**")
    st.write(f"- æ½›åŠ›ï¼ˆgrowth_potentialï¼‰ï¼š**{gp} / 5**")
    st.markdown("#### ğŸ“ æ•´é«”è©•è«–")
    st.write(overall.get("summary", "N/A"))

    st.markdown("### ğŸ“Œ æœ¬æ¬¡é¢è©¦é›·é”åœ–")
    categories = ["technical", "communication", "structure", "relevance", "problem_solving", "growth_potential"]
    labels_zh = ["æŠ€è¡“", "è¡¨é”", "çµæ§‹", "ç›¸é—œ", "è§£é¡Œ", "æ½›åŠ›"]
    scores = [tech, comm, struct, rel, ps, gp]
    
    # ä¿®æ­£ç¶­åº¦ä¸åŒ¹é…çš„ bug
    values = scores + scores[:1]
    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
    angles += angles[:1]

    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw={"polar": True})
    ax.plot(angles, values, linewidth=2)
    ax.fill(angles, values, alpha=0.25)
    ax.set_thetagrids(np.degrees(angles[:-1]), labels_zh)
    ax.set_ylim(0, 5)
    plt.tight_layout()
    st.pyplot(fig)

    if st.session_state.selected_history_interview_id:
        ref_scores = get_scores(st.session_state.selected_history_interview_id)
        st.markdown("### ğŸ”„ èˆ‡æ­·å²é¢è©¦æ¯”è¼ƒ")
        if ref_scores:
            ref_vals = [ref_scores.get(k, 0) for k in categories]
            ref_plot = ref_vals + ref_vals[:1]
            fig2, ax2 = plt.subplots(figsize=(6, 6), subplot_kw={"polar": True})
            ax2.plot(angles, ref_plot, "r--", label="æ­·å²")
            ax2.plot(angles, values, "b-", label="æœ¬æ¬¡")
            ax2.fill(angles, values, alpha=0.25)
            ax2.set_thetagrids(angles[:-1] * 180 / np.pi, labels_zh)
            ax2.legend(loc="upper right", bbox_to_anchor=(1.2, 1.1))
            ax2.set_ylim(0, 5)
            plt.tight_layout()
            st.pyplot(fig2)
            st.caption("è™›ç·šï¼šæ­·å²ç´€éŒ„ï¼›å¯¦ç·šï¼šæœ¬æ¬¡é¢è©¦")

    st.markdown("### ğŸ“ é€é¡Œå›é¥‹")
    for i, item in enumerate(per_question):
        s = item.get("score", {})
        st.markdown(f"#### ç¬¬ {i+1} é¡Œ")
        st.markdown(f"**é¡Œç›®ï¼š** {item.get('question', 'N/A')}")
        st.markdown(f"**å›ç­”ï¼š** {item.get('answer', 'N/A')}")
        st.write(f"æŠ€è¡“ {s.get('technical',0)}/5 ï½œ è¡¨é” {s.get('communication',0)}/5 ï½œ çµæ§‹ {s.get('structure',0)}/5 ï½œ ç›¸é—œ {s.get('relevance',0)}/5 ï½œ è§£é¡Œ {s.get('problem_solving',0)}/5 ï½œ æ½›åŠ› {s.get('growth_potential',0)}/5")
        st.markdown(f"**å›é¥‹ï¼š** {item.get('feedback', 'N/A')}")
        st.markdown("---")

    if st.session_state.voice_analysis_results:
        st.markdown("### ğŸ¤ é€é¡ŒèªéŸ³ç‰¹å¾µå›é¥‹")
        for i, r in enumerate(st.session_state.voice_analysis_results):
            if r:
                st.markdown(f"#### ç¬¬ {i+1} é¡Œçš„èªéŸ³")
                if "error" in r:
                    st.warning(r["error"])
                else:
                    st.write(f"- **éŸ³èª¿åˆ†æ**ï¼š{r['pitch']}")
                    st.write(f"- **éŸ³é‡åˆ†æ**ï¼š{r['volume']}")
                    st.write(f"- **èªé€Ÿåˆ†æ**ï¼š{r['speech_rate']}")
                st.markdown("---")
    
    if st.session_state.suggestions:
        st.markdown("### ğŸ’¡ å€‹äººåŒ–å»ºè­°")
        st.markdown(st.session_state.suggestions)
        st.markdown("---")

    st.markdown("### ğŸ’¾ ä¸‹è¼‰é¢è©¦å ±å‘Š")
    
    radar_image_buffer = io.BytesIO()
    fig.savefig(radar_image_buffer, format='PNG', dpi=300)
    radar_image_buffer.seek(0)

    report_data = {
        "candidate_id": st.session_state.candidate_id,
        "job_role": job_role,
        "timestamp": datetime.now().strftime("%Y-%m-%d"),
        "overall_scores": overall,
        "summary": overall.get("summary", "N/A"),
        "radar_chart_image": radar_image_buffer.read(),
        "qa_list": st.session_state.qa_list,
        "per_question_feedback": per_question,
        "voice_analysis_results": st.session_state.voice_analysis_results,
        "suggestions": st.session_state.suggestions,
    }

    pdf_bytes = None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            export_pdf(tmp.name, report_data)
            with open(tmp.name, "rb") as f:
                pdf_bytes = f.read()
    except Exception as e:
        st.error(f"ç”¢ç”Ÿ PDF å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    if pdf_bytes:
        st.download_button("ğŸ“„ ä¸‹è¼‰ç²¾ç·» PDF å ±å‘Š", data=pdf_bytes, file_name="interview_report_detailed.pdf", mime="application/pdf")

    def build_report_md():
        lines = ["# AI é¢è©¦å®˜ç·´ç¿’å ±å‘Š", f"- å—è©¦è€…ï¼š{st.session_state.candidate_id}", f"- è·ç¼ºï¼š{job_role}", f"- æ—¥æœŸï¼š{datetime.now().strftime('%Y-%m-%d')}\n"]
        lines.append("## æ•´é«”è©•åˆ†")
        lines.append(f"- æŠ€è¡“ï¼š{tech}/5, è¡¨é”ï¼š{comm}/5, çµæ§‹ï¼š{struct}/5, ç›¸é—œï¼š{rel}/5, è§£é¡Œï¼š{ps}/5, æ½›åŠ›ï¼š{gp}/5\n")
        lines.append("## æ•´é«”è©•è«–\n" + overall.get("summary", "N/A") + "\n")
        lines.append("## é€é¡Œå›é¥‹")
        for i, item in enumerate(per_question):
            sc = item.get("score", {})
            lines.extend([f"### ç¬¬ {i+1} é¡Œ", f"- é¡Œç›®ï¼š{item.get('question', 'N/A')}", f"- å›ç­”ï¼š{item.get('answer', 'N/A')}", f"- åˆ†æ•¸ï¼šæŠ€è¡“ {sc.get('technical',0)}/5, è¡¨é” {sc.get('communication',0)}/5, çµæ§‹ {sc.get('structure',0)}/5, ç›¸é—œ {sc.get('relevance',0)}/5, è§£é¡Œ {sc.get('problem_solving',0)}/5, æ½›åŠ› {sc.get('growth_potential',0)}/5", f"- å›é¥‹ï¼š{item.get('feedback', 'N/A')}\n"])
        if st.session_state.suggestions:
            lines.extend(["## å€‹äººåŒ–å»ºè­°\n", st.session_state.suggestions])
        return "\n".join(lines)

    report_md = build_report_md()
    st.download_button("ğŸ“„ ä¸‹è¼‰ Markdown å ±å‘Š", data=report_md, file_name="interview_report.md", mime="text/markdown")
    html_content = export_html(report_md)
    st.download_button("ğŸŒ ä¸‹è¼‰ HTML å ±å‘Š", data=html_content, file_name="interview_report.html", mime="text/html")