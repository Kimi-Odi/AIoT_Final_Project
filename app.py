import os
import json
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
import librosa

# è‡ªè¨‚æ¨¡çµ„
from resume_parser import parse_resume
from grader import grade_interview
from pdf_export import export_pdf
from html_export import export_html
from db import (
    init_db,
    save_candidate,
    save_interview,
    save_qa,
    save_scores,
    get_interviews,
    get_scores,
    get_qa
)

# ====== åˆå§‹åŒ–èˆ‡è¨­å®š ======
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("è«‹åœ¨ .env è¨­å®š OPENAI_API_KEY")

client = OpenAI(api_key=api_key)

# å­—å‹
matplotlib.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]
matplotlib.rcParams["axes.unicode_minus"] = False

# åˆå§‹åŒ–è³‡æ–™åº«
init_db()

# ====== èªéŸ³åŠŸèƒ½ ======
def synthesize_speech(text: str) -> bytes:
    try:
        resp = client.audio.speech.create(
            model="gpt-4o-mini-tts",
            voice="alloy",
            input=text,
        )
        return resp.read()
    except Exception as e:
        st.error(f"TTS éŒ¯èª¤ï¼š{e}")
        return None

def speech_to_text(file) -> str:
    try:
        resp = client.audio.transcriptions.create(
            model="whisper-1",
            file=file,
            response_format="verbose_json"  # â­ å–å¾—æ¯æ®µ timestamps
        )
        return resp.text
    except Exception as e:
        st.error(f"Whisper éŒ¯èª¤ï¼š{e}")
        return ""

FILLERS = ["å—¯", "å‘ƒ", "é‚£å€‹", "å°±æ˜¯", "ä½ çŸ¥é“", "like", "you know", "um", "uh"]

def analyze_speech_features(whisper_resp, audio_bytes):
    result = {}

    # ======================
    # 1) èªé€Ÿ WPM
    # ======================
    total_words = len(whisper_resp["text"].split())
    total_time = whisper_resp["segments"][-1]["end"] - whisper_resp["segments"][0]["start"]
    wpm = (total_words / total_time) * 60 if total_time > 0 else 0
    result["wpm"] = round(wpm, 2)

    # ======================
    # 2) åœé “æ¯”ä¾‹ï¼ˆsilence ratioï¼‰
    # ======================
    silences = []
    segs = whisper_resp["segments"]
    for i in range(1, len(segs)):
        gap = segs[i]["start"] - segs[i-1]["end"]
        if gap > 0.2:   # >0.2s è¦–ç‚ºåœé “
            silences.append(gap)

    total_silence = sum(silences)
    result["silence_ratio"] = round(total_silence / total_time, 3)

    # ======================
    # 3) éŸ³é‡ç©©å®šåº¦ï¼ˆVolume Stabilityï¼‰
    # ======================
    # è®€å–éŸ³è¨Šç‚º numpy é™£åˆ—
    import soundfile as sf
    import io
    y, sr = sf.read(io.BytesIO(audio_bytes))

    frame = librosa.feature.rms(y=y)[0]  # Root Mean Square energy
    vol_std = np.std(frame)
    vol_mean = np.mean(frame)
    stability = 1 - (vol_std / (vol_mean + 1e-9))
    result["volume_stability"] = round(float(stability), 3)

    # ======================
    # 4) å¡«å……è©æ¯”ä¾‹ filler ratio
    # ======================
    filler_count = 0
    for f in FILLERS:
        filler_count += whisper_resp["text"].count(f)

    filler_ratio = filler_count / max(total_words, 1)
    result["filler_ratio"] = round(filler_ratio, 3)

    return result


# ====== RAG ======
class SimpleRAG:
    def __init__(self, folder="knowledge"):
        self.docs = []
        if not os.path.isdir(folder):
            return
        for fname in os.listdir(folder):
            if fname.endswith(".md"):
                with open(os.path.join(folder, fname), "r", encoding="utf-8") as f:
                    self.docs.append((fname, f.read()))

    def retrieve(self, job: str, query: str, top_k=3):
        if not self.docs:
            return []
        q = query.lower()
        scored = []
        for name, text in self.docs:
            score = sum(q.count(tok) for tok in q.split() if tok in text.lower())
            scored.append((score, name, text))
        scored.sort(reverse=True, key=lambda x: x[0])
        return [x[2] for x in scored[:top_k] if x[0] > 0]

@st.cache_resource
def get_rag():
    return SimpleRAG("knowledge")

rag = get_rag()

# ====== Streamlit UI ======
st.set_page_config(page_title="AI è™›æ“¬é¢è©¦å®˜", page_icon="ğŸ§‘â€ğŸ«")
st.title("ğŸ§‘â€ğŸ« AI è™›æ“¬é¢è©¦å®˜ï¼ˆå±¥æ­· + RAG + èªéŸ³ + æ­·å²ç´€éŒ„ï¼‰")

# ====== Session State ======
def init_state(k, v):
    if k not in st.session_state:
        st.session_state[k] = v

init_state("messages", [])
init_state("started", False)
init_state("resume_info", None)
init_state("candidate_id", "")
init_state("qa_list", [])
init_state("last_question", None)
init_state("grade_result", None)
init_state("selected_history_interview_id", None)
init_state("voice_mode", False)
init_state("play_tts_first_question", False)


# ====== Sidebar ======
with st.sidebar:
    st.header("é¢è©¦è¨­å®š")

    candidate_id = st.text_input(
        "å—è©¦è€… IDï¼ˆå§“å / å­¸è™Ÿï¼‰",
        value=st.session_state.candidate_id,
    )
    st.session_state.candidate_id = candidate_id

    if candidate_id:
        save_candidate(candidate_id)

    job_role = st.selectbox(
        "æ‡‰å¾µè·ç¼º",
        ["å¾Œç«¯å·¥ç¨‹å¸«", "AI å·¥ç¨‹å¸«", "è³‡æ–™å·¥ç¨‹å¸«", "å‰ç«¯å·¥ç¨‹å¸«"],
    )

    interview_style = st.selectbox(
        "é¢è©¦é¢¨æ ¼", ["æ™®é€š", "åš´æ ¼", "æº«å’Œ"]
    )

    st.markdown("---")
    st.subheader("ä¸Šå‚³å±¥æ­·ï¼ˆPDFï¼‰")
    uploaded_resume = st.file_uploader("PDF å±¥æ­·", type=["pdf"])

    st.markdown("---")
    st.subheader("èªéŸ³æ¨¡å¼")
    st.session_state.voice_mode = st.checkbox("å•Ÿç”¨èªéŸ³ï¼ˆTTS + Whisperï¼‰", value=False)

    st.markdown("---")
    st.subheader("æ­·å²ç´€éŒ„")
    history_list = []
    if candidate_id:
        history_list = get_interviews(candidate_id)
        if history_list:
            labels = [f"{h['timestamp']}ï½œ{h['job_role']}" for h in history_list]
            idx = st.session_state.selected_history_interview_id
            default_idx = 0
            if idx:
                for i, h in enumerate(history_list):
                    if h["interview_id"] == idx:
                        default_idx = i
                        break

            picked = st.selectbox("é¸æ“‡ç´€éŒ„ï¼š", labels, index=default_idx)
            st.session_state.selected_history_interview_id = history_list[
                labels.index(picked)
            ]["interview_id"]
        else:
            st.caption("æ­¤å—è©¦è€…ç›®å‰æ²’æœ‰æ­·å²è³‡æ–™")
    else:
        st.caption("è«‹è¼¸å…¥å—è©¦è€… ID æ‰èƒ½æŸ¥è©¢æ­·å²ç´€éŒ„")

    st.markdown("---")
    reset_btn = st.button("ğŸ” é‡ç½®æœ¬æ¬¡é¢è©¦")


# --------------------------------------------------------
# é‡ç½®ç‹€æ…‹
# --------------------------------------------------------
if reset_btn:
    st.session_state.messages = []
    st.session_state.started = False
    st.session_state.resume_info = None
    st.session_state.qa_list = []
    st.session_state.last_question = None
    st.session_state.grade_result = None
    st.session_state.selected_history_interview_id = None
    st.rerun()

# --------------------------------------------------------
# å±¥æ­·è§£æï¼ˆPDF â†’ JSONï¼‰
# --------------------------------------------------------
if uploaded_resume and st.session_state.resume_info is None:
    with st.spinner("AI æ­£åœ¨è§£æå±¥æ­·â€¦"):
        st.session_state.resume_info = parse_resume(uploaded_resume)
    st.success("å±¥æ­·è§£æå®Œæˆï¼")

# å±•é–‹å±¥æ­·æ‘˜è¦
with st.expander("ğŸ“„ å±¥æ­·è§£æçµæœ"):
    ri = st.session_state.resume_info
    if ri:
        st.markdown("### ğŸ§© æŠ€èƒ½")
        st.write(", ".join(ri.get("skills", [])) or "ï¼ˆç„¡ï¼‰")

        st.markdown("### ğŸ“š å°ˆæ¡ˆ")
        for p in ri.get("projects", []):
            st.markdown(f"**{p['title']}** â€” {p['description']}")
            st.write("æŠ€è¡“ï¼š", ", ".join(p.get("tech_stack", [])))

        st.markdown("### ğŸ’¼ å·¥ä½œç¶“é©—")
        for w in ri.get("work_experience", []):
            st.markdown(f"**{w['company']} / {w['position']} ({w['duration']})**")
            st.write(w["description"])

        st.markdown("### ğŸ“ å­¸æ­·")
        for e in ri.get("education", []):
            st.markdown(f"{e['school']} â€” {e['degree']} ({e['duration']})")

        st.markdown("### ğŸ“ è‡ªæˆ‘æ‘˜è¦")
        st.write(ri.get("summary", "ï¼ˆç„¡ï¼‰"))
    else:
        st.caption("å°šæœªä¸Šå‚³å±¥æ­·ã€‚")


# --------------------------------------------------------
# Prompt çµ„åˆå™¨ï¼ˆå«é›»è³‡ RAGï¼‰
# --------------------------------------------------------
def build_system_prompt(job: str, style: str, resume_info=None, rag_snippets=None):

    style_map = {
        "æ™®é€š": "èªæ°£å°ˆæ¥­ã€æ­£å¸¸é¢è©¦æµç¨‹ã€‚",
        "åš´æ ¼": "èªæ°£ç›´æ¥ã€æœ‰å£“åŠ›ã€æ·±åº¦è¿½å•ã€‚",
        "æº«å’Œ": "èªæ°£å‹å–„ã€è¬›è§£å¼ã€é¼“å‹µå­¸ç”Ÿã€‚",
    }
    style_desc = style_map[style]

    resume_context = ""
    if resume_info:
        skills = ", ".join(resume_info.get("skills", []))
        resume_context += f"å€™é¸äººæŠ€èƒ½ï¼š{skills or 'ï¼ˆç„¡ï¼‰'}\n"

        if resume_info.get("projects"):
            resume_context += "å°ˆæ¡ˆç¶“é©—ï¼š\n"
            for p in resume_info["projects"]:
                resume_context += f"- {p['title']}: {p['description']}\n"

        summary = resume_info.get("summary", "")
        if summary:
            resume_context += f"è‡ªæˆ‘ä»‹ç´¹æ‘˜è¦ï¼š{summary}\n"

    rag_context = ""
    if rag_snippets:
        rag_context += "\nä»¥ä¸‹ç‚ºèˆ‡è·ç¼ºç›¸é—œçš„é‡è¦æŠ€è¡“çŸ¥è­˜ç‰‡æ®µï¼ˆRAGï¼‰ï¼š\n"
        for i, snip in enumerate(rag_snippets, start=1):
            rag_context += f"[ç‰‡æ®µ {i}]\n{snip}\n\n"

    return f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­ã€Œ{job}ã€é ˜åŸŸçš„é¢è©¦å®˜ã€‚

è«‹éµå®ˆä»¥ä¸‹åŸå‰‡ï¼š
1. ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
2. æ¯æ¬¡åªå•ä¸€é¡Œã€‚
3. è‹¥å€™é¸äººå›ç­”ä¸å®Œæ•´ï¼Œé©åº¦è¿½å•æŠ€è¡“ç´°ç¯€ã€‚
4. é¢¨æ ¼ï¼š{style_desc}
5. é¡Œç›®æ·±åº¦æ¯”ä¸€èˆ¬é¢è©¦æ›´åå·¥ç¨‹å¯¦ä½œã€æŠ€è¡“ç†è§£ã€‚

æ ¹æ“šä»¥ä¸‹å€™é¸äººè³‡è¨Šèˆ‡èƒŒæ™¯ï¼š
{resume_context}

{rag_context}

è«‹é–‹å§‹é¢è©¦ï¼Œç¬¬ä¸€é¡Œè«‹å°æ–¹è‡ªæˆ‘ä»‹ç´¹ã€‚
""".strip()


# --------------------------------------------------------
# LLM ä¸»å›è¦† functionï¼ˆå« RAG + ä¸Šä¸€è¼ª Q/Aï¼‰
# --------------------------------------------------------
def call_llm(job: str, style: str, history, resume_info=None):

    # ===== ç”¢ç”Ÿ RAG æŸ¥è©¢ =====
    query_parts = [f"è·ç¼ºï¼š{job}"]

    last_q, last_a = None, None
    for role, msg in reversed(history):
        if role == "assistant" and last_q is None:
            last_q = msg
        elif role == "user" and last_a is None:
            last_a = msg
        if last_q and last_a:
            break

    if last_q:
        query_parts.append("ä¸Šä¸€é¡Œï¼š" + last_q[:100])
    if last_a:
        query_parts.append("ä¸Šä¸€ç­”ï¼š" + last_a[:100])

    if resume_info:
        skills = resume_info.get("skills", [])
        if skills:
            query_parts.append("æŠ€èƒ½ï¼š" + ", ".join(skills))

    rag_query = "ï¼›".join(query_parts)

    # ===== é›»è³‡è·ç¼º RAG æ¬Šé‡ =====
    role_map = {
        "å¾Œç«¯å·¥ç¨‹å¸«": ["algorithms", "datastructures", "system_design", "database"],
        "AI å·¥ç¨‹å¸«": ["ai_ml", "algorithms", "computer_arch"],
        "è³‡æ–™å·¥ç¨‹å¸«": ["database", "system_design"],
        "å‰ç«¯å·¥ç¨‹å¸«": ["algorithms", "system_design"],
    }
    preferred_tags = role_map.get(job, [])

    raw_snips = rag.retrieve(job, rag_query, top_k=5)
    rag_snippets = sorted(
        raw_snips,
        key=lambda x: any(tag in x.lower() for tag in preferred_tags),
        reverse=True
    )[:3]

    # ===== Build system prompt =====
    system_prompt = build_system_prompt(
        job,
        style,
        resume_info=resume_info,
        rag_snippets=rag_snippets,
    )

    # ===== å‘¼å« OpenAI =====
    msgs = [{"role": "system", "content": system_prompt}]
    for r, c in history:
        msgs.append({"role": r, "content": c})

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=msgs,
    )
    return resp.choices[0].message.content


# --------------------------------------------------------
# é¡¯ç¤ºæ­·å²è¨Šæ¯ï¼ˆèŠå¤©æ¡†ï¼‰
# --------------------------------------------------------
for role, content in st.session_state.messages:
    st.chat_message(role).markdown(content)
    # ===== ç¬¬ä¸€é¡Œ TTS æ’­æ”¾ =====
    if st.session_state.get("play_tts_first_question", False):
        st.session_state.play_tts_first_question = False  # æ’­ä¸€æ¬¡å°±é—œæ‰
        first_question = st.session_state.last_question
        audio_bytes = synthesize_speech(first_question)
        if audio_bytes:
            st.audio(audio_bytes, format="audio/mp3")



# --------------------------------------------------------
# é¢è©¦ä¸»æµç¨‹ï¼ˆå°šæœªé–‹å§‹ï¼‰
# --------------------------------------------------------
if not st.session_state.started:
    if st.button("â–¶ï¸ é–‹å§‹é¢è©¦"):

        first_reply = call_llm(
            job_role,
            interview_style,
            [],
            resume_info=st.session_state.resume_info,
        )

        st.session_state.messages.append(("assistant", first_reply))
        st.session_state.last_question = first_reply
        st.session_state.started = True

        # â­è¨­å®šæ——æ¨™ï¼Œä¸‹ä¸€è¼ª render æ’­æ”¾ TTS
        if st.session_state.voice_mode:
            st.session_state.play_tts_first_question = True

        st.rerun()




# --------------------------------------------------------
# é¢è©¦å·²é–‹å§‹ â†’ ä½¿ç”¨è€…å›ç­”
# --------------------------------------------------------
else:
    st.markdown("### å›ç­”æœ¬é¡Œ")

    # ===== ä½¿ç”¨è€…èªéŸ³å›ç­”ï¼ˆéŒ„éŸ³ + Whisperï¼‰ =====
    st.markdown("### ğŸ¤ èªéŸ³å›ç­”ï¼ˆéŒ„éŸ³ï¼‰")

    audio_rec = st.audio_input("æŒ‰ä¸‹é–‹å§‹éŒ„éŸ³ â†’ å°è‘—éº¥å…‹é¢¨å›ç­”")

    voice_answer = None

    if audio_rec:
        with st.spinner("Whisper æ­£åœ¨è¾¨è­˜ä½ çš„èªéŸ³â€¦"):
            whisper_resp = speech_to_text(audio_rec)
            voice_answer = whisper_resp["text"]

            # ===== èªéŸ³ç‰¹å¾µåˆ†æ =====
            analysis = analyze_speech_features(whisper_resp, audio_rec.getvalue())

            st.markdown("### ğŸ“Š èªéŸ³ç‰¹å¾µåˆ†æ")
            st.write(f"- èªé€Ÿï¼ˆWPMï¼‰ï¼š{analysis['wpm']}")
            st.write(f"- åœé “æ¯”ä¾‹ï¼š{analysis['silence_ratio']}")
            st.write(f"- éŸ³é‡ç©©å®šåº¦ï¼š{analysis['volume_stability']}")
            st.write(f"- å¡«å……è©æ¯”ä¾‹ï¼š{analysis['filler_ratio']}")

        if voice_answer:
            st.success("èªéŸ³è¾¨è­˜æˆåŠŸï¼")
            st.write("ä½ çš„èªéŸ³å…§å®¹ï¼š", voice_answer)

    # ===== èˆŠçš„ä¸Šå‚³æª”æ¡ˆåŠŸèƒ½ï¼ˆä»ä¿ç•™ï¼‰ =====
    audio_file = st.file_uploader("ï¼ˆå¯é¸ï¼‰ä¸Šå‚³èªéŸ³æª” mp3/wav/m4a", type=["mp3","wav","m4a"])
    if audio_file and not voice_answer:
        with st.spinner("Whisper æ­£åœ¨è¾¨è­˜ä½ çš„èªéŸ³â€¦"):
            voice_answer = speech_to_text(audio_file)
        if voice_answer:
            st.success("èªéŸ³è¾¨è­˜æˆåŠŸï¼")
            st.write("ä½ çš„èªéŸ³å…§å®¹ï¼š", voice_answer)


    # ====== æ–‡å­—å›ç­” ======
    text_answer = st.chat_input("è«‹è¼¸å…¥ä½ çš„å›ç­”â€¦")

    # èªéŸ³å„ªå…ˆæ–¼æ–‡å­—
    user_input = voice_answer if voice_answer else text_answer

    # è‹¥æ²’æœ‰å›ç­”ï¼ˆèªéŸ³/æ–‡å­—ï¼‰å‰‡ä¸é€²è¡Œ
    if user_input:
        # è¨˜éŒ„ QAï¼ˆä¸Šä¸€é¡Œ + ä½¿ç”¨è€…çš„å›ç­”ï¼‰
        if st.session_state.last_question:
            st.session_state.qa_list.append({
                "question": st.session_state.last_question,
                "answer": user_input,
            })

        # é¡¯ç¤ºä½¿ç”¨è€…å›ç­”
        st.session_state.messages.append(("user", user_input))
        st.chat_message("user").markdown(user_input)

        # å‘¼å«é¢è©¦å®˜
        assistant_reply = call_llm(
            job_role,
            interview_style,
            st.session_state.messages,
            resume_info=st.session_state.resume_info,
        )

        # é¡¯ç¤º AI å›è¦†
        st.session_state.messages.append(("assistant", assistant_reply))
        st.chat_message("assistant").markdown(assistant_reply)

        # æ›´æ–° last_question
        st.session_state.last_question = assistant_reply

        # ===== é¢è©¦å®˜èªéŸ³å‡ºé¡Œï¼ˆTTSï¼‰ =====
        if st.session_state.voice_mode:
            tts_audio = synthesize_speech(assistant_reply)
            if tts_audio:
                st.audio(tts_audio, format="audio/mp3")


# --------------------------------------------------------
# è©•åˆ†æŒ‰éˆ•
# --------------------------------------------------------
st.markdown("---")
st.subheader("ğŸ“Š é¢è©¦è©•åˆ†")

if st.button("ğŸ“Š çµæŸé¢è©¦ä¸¦é€²è¡Œ AI è©•åˆ†"):
    if not st.session_state.qa_list:
        st.warning("å°šæœªå›ç­”ä»»ä½•é¡Œç›®ï¼Œç„¡æ³•è©•åˆ†ã€‚")
    else:
        with st.spinner("AI æ­£åœ¨åˆ†æä½ çš„æ•´å ´é¢è©¦â€¦"):
            # ç”¢ç”Ÿè©•åˆ†
            result = grade_interview(
                st.session_state.qa_list,
                job_role,
                st.session_state.resume_info,
            )
            st.session_state.grade_result = result

            # å„²å­˜åˆ°è³‡æ–™åº« interview.db
            if st.session_state.candidate_id:
                interview_id = save_interview(
                    candidate_id=st.session_state.candidate_id,
                    job_role=job_role,
                    timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    summary=result["overall"]["summary"],
                )

                # å„²å­˜ QA
                for qa in st.session_state.qa_list:
                    save_qa(interview_id, qa["question"], qa["answer"])

                # å„²å­˜åˆ†æ•¸
                save_scores(interview_id, result["overall"])

        st.success("è©•åˆ†å®Œæˆï¼è«‹å‘ä¸‹æŸ¥çœ‹çµæœã€‚")


# --------------------------------------------------------
# é¡¯ç¤ºè©•åˆ†çµæœ
# --------------------------------------------------------
if st.session_state.grade_result:

    result = st.session_state.grade_result
    overall = result["overall"]
    per_question = result["per_question"]

    # ä¸»åˆ†æ•¸
    tech = overall["technical"]
    comm = overall["communication"]
    struct = overall["structure"]
    rel = overall["relevance"]
    ps = overall["problem_solving"]
    gp = overall["growth_potential"]

    st.markdown("### â­ æ•´é«”è©•åˆ†")

    st.write(f"- æŠ€è¡“ï¼ˆtechnicalï¼‰ï¼š**{tech} / 5**")
    st.write(f"- è¡¨é”ï¼ˆcommunicationï¼‰ï¼š**{comm} / 5**")
    st.write(f"- çµæ§‹ï¼ˆstructureï¼‰ï¼š**{struct} / 5**")
    st.write(f"- ç›¸é—œæ€§ï¼ˆrelevanceï¼‰ï¼š**{rel} / 5**")
    st.write(f"- è§£é¡Œèƒ½åŠ›ï¼ˆproblem_solvingï¼‰ï¼š**{ps} / 5**")
    st.write(f"- æ½›åŠ›ï¼ˆgrowth_potentialï¼‰ï¼š**{gp} / 5**")

    st.markdown("#### ğŸ“ æ•´é«”è©•è«–")
    st.write(overall["summary"])

    # --------------------------------------------------------
    # ğŸ“ˆ æœ¬æ¬¡é¢è©¦é›·é”åœ–
    # --------------------------------------------------------
    st.markdown("### ğŸ“Œ æœ¬æ¬¡é¢è©¦é›·é”åœ–")

    categories = ["technical", "communication", "structure",
                  "relevance", "problem_solving", "growth_potential"]
    labels_zh = ["æŠ€è¡“", "è¡¨é”", "çµæ§‹", "ç›¸é—œ", "è§£é¡Œ", "æ½›åŠ›"]

    scores = [tech, comm, struct, rel, ps, gp]
    values = scores + scores[:1]
    angles = np.linspace(0, 2 * np.pi, len(categories) + 1)

    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw={"polar": True})
    ax.plot(angles, values, linewidth=2)
    ax.fill(angles, values, alpha=0.25)
    ax.set_thetagrids(angles[:-1] * 180 / np.pi, labels_zh)
    ax.set_ylim(0, 5)
    plt.tight_layout()
    st.pyplot(fig)

    # --------------------------------------------------------
    # ğŸ”„ èˆ‡æ­·å²ç´€éŒ„æ¯”è¼ƒé›·é”åœ–ï¼ˆè‹¥æœ‰é¸å–ï¼‰
    # --------------------------------------------------------
    if st.session_state.selected_history_interview_id:
        ref_scores = get_scores(st.session_state.selected_history_interview_id)

        st.markdown("### ğŸ”„ èˆ‡æ­·å²é¢è©¦æ¯”è¼ƒ")

        if ref_scores:
            ref_vals = [
                ref_scores["technical"],
                ref_scores["communication"],
                ref_scores["structure"],
                ref_scores["relevance"],
                ref_scores["problem_solving"],
                ref_scores["growth_potential"],
            ]
            cur_vals = scores
            ref_plot = ref_vals + ref_vals[:1]
            cur_plot = cur_vals + cur_vals[:1]

            fig2, ax2 = plt.subplots(figsize=(6, 6), subplot_kw={"polar": True})
            ax2.plot(angles, ref_plot, "r--", label="æ­·å²")
            ax2.plot(angles, cur_plot, "b-", label="æœ¬æ¬¡")
            ax2.fill(angles, cur_plot, alpha=0.25)
            ax2.set_thetagrids(angles[:-1] * 180 / np.pi, labels_zh)
            ax2.legend(loc="upper right", bbox_to_anchor=(1.2, 1.1))
            ax2.set_ylim(0, 5)

            plt.tight_layout()
            st.pyplot(fig2)
            st.caption("è™›ç·šï¼šæ­·å²ç´€éŒ„ï¼›å¯¦ç·šï¼šæœ¬æ¬¡é¢è©¦")

    # --------------------------------------------------------
    # é€é¡Œå›é¥‹
    # --------------------------------------------------------
    st.markdown("### ğŸ“ é€é¡Œå›é¥‹")

    for i, item in enumerate(per_question, start=1):
        s = item["score"]
        st.markdown(f"#### ç¬¬ {i} é¡Œ")
        st.markdown(f"**é¡Œç›®ï¼š** {item['question']}")
        st.markdown(f"**å›ç­”ï¼š** {item['answer']}")
        st.write(
            f"æŠ€è¡“ {s['technical']}/5 ï½œ è¡¨é” {s['communication']}/5 ï½œ "
            f"çµæ§‹ {s['structure']}/5 ï½œ ç›¸é—œ {s['relevance']}/5 ï½œ "
            f"è§£é¡Œ {s['problem_solving']}/5 ï½œ æ½›åŠ› {s['growth_potential']}/5"
        )
        st.markdown(f"**å›é¥‹ï¼š** {item['feedback']}")
        st.markdown("---")


    # --------------------------------------------------------
    # é¢è©¦å ±å‘Šä¸‹è¼‰ï¼ˆMD / PDF / HTMLï¼‰
    # --------------------------------------------------------
    st.markdown("### ğŸ’¾ ä¸‹è¼‰é¢è©¦å ±å‘Š")

    def build_report_md():
        lines = []
        lines.append("# AI é¢è©¦å®˜ç·´ç¿’å ±å‘Š\n")
        lines.append(f"- å—è©¦è€…ï¼š{st.session_state.candidate_id}")
        lines.append(f"- è·ç¼ºï¼š{job_role}")
        lines.append(f"- æ—¥æœŸï¼š{datetime.now().strftime('%Y-%m-%d')}\n")

        lines.append("## æ•´é«”è©•åˆ†")
        lines.append(f"- æŠ€è¡“ï¼š{tech}/5")
        lines.append(f"- è¡¨é”ï¼š{comm}/5")
        lines.append(f"- çµæ§‹ï¼š{struct}/5")
        lines.append(f"- ç›¸é—œï¼š{rel}/5")
        lines.append(f"- è§£é¡Œï¼š{ps}/5")
        lines.append(f"- æ½›åŠ›ï¼š{gp}/5\n")

        lines.append("## æ•´é«”è©•è«–\n" + overall["summary"] + "\n")

        lines.append("## é€é¡Œå›é¥‹")
        for i, item in enumerate(per_question, start=1):
            sc = item["score"]
            lines.append(f"### ç¬¬ {i} é¡Œ")
            lines.append(f"- é¡Œç›®ï¼š{item['question']}")
            lines.append(f"- å›ç­”ï¼š{item['answer']}")
            lines.append(
                f"- åˆ†æ•¸ï¼šæŠ€è¡“ {sc['technical']}/5ï¼Œè¡¨é” {sc['communication']}/5ï¼Œ"
                f"çµæ§‹ {sc['structure']}/5ï¼Œç›¸é—œ {sc['relevance']}/5ï¼Œ"
                f"è§£é¡Œ {sc['problem_solving']}/5ï¼Œæ½›åŠ› {sc['growth_potential']}/5"
            )
            lines.append(f"- å›é¥‹ï¼š{item['feedback']}\n")
        return "\n".join(lines)

    report_md = build_report_md()

    # Markdown ä¸‹è¼‰
    st.download_button(
        "ğŸ“„ ä¸‹è¼‰ Markdown å ±å‘Š",
        data=report_md,
        file_name="interview_report.md",
        mime="text/markdown",
    )

    # PDF ä¸‹è¼‰
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        export_pdf(tmp.name, report_md)
        with open(tmp.name, "rb") as f:
            pdf_bytes = f.read()

    st.download_button(
        "ğŸ“„ ä¸‹è¼‰ PDF å ±å‘Š",
        data=pdf_bytes,
        file_name="interview_report.pdf",
        mime="application/pdf",
    )

    # HTML ä¸‹è¼‰
    html_content = export_html(report_md)
    st.download_button(
        "ğŸŒ ä¸‹è¼‰ HTML å ±å‘Š",
        data=html_content,
        file_name="interview_report.html",
        mime="text/html",
    )
