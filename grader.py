# ================================================================
# grader.py â€” AI è™›æ“¬é¢è©¦å®˜è©•åˆ†æ¨¡çµ„ï¼ˆå«èªéŸ³ç‰¹å¾µèª¿æ•´ + èªéŸ³æ”¹å–„å»ºè­°ï¼‰
# ================================================================

import os
import json
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api.getenv("OPENAI_API_KEY"))

# ================================================================
# ğŸ”¹ èªéŸ³ç‰¹å¾µèª¿æ•´ï¼ˆB åŠŸèƒ½ï¼‰
# ================================================================
def speech_feature_adjustment(features):
    """
    å°‡èªéŸ³ç‰¹å¾µæ˜ å°„ç‚º 0.6ï½1.0 è©•åˆ†ä¿‚æ•¸
    å›å‚³ floatï¼Œå½±éŸ¿ communication èˆ‡ structure åˆ†æ•¸
    """
    if not features:
        return 1.0  # ç„¡èªéŸ³ â†’ ä¸èª¿æ•´

    wpm = features["wpm"]
    silence = features["silence_ratio"]
    stability = features["volume_stability"]
    filler = features["filler_ratio"]

    # ----------------------------------------
    # WPM èªé€Ÿï¼ˆ100~180 ç‚ºæ­£å¸¸ï¼‰
    # ----------------------------------------
    if wpm < 80:
        wpm_score = 0.7
    elif 80 <= wpm <= 180:
        wpm_score = 1.0
    else:
        wpm_score = 0.8

    # ----------------------------------------
    # åœé “ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰
    # ----------------------------------------
    if silence < 0.1:
        silence_score = 1.0
    elif silence < 0.25:
        silence_score = 0.85
    else:
        silence_score = 0.65

    # ----------------------------------------
    # éŸ³é‡ç©©å®šåº¦ï¼ˆ0~1ï¼‰
    # ----------------------------------------
    stability_score = min(max(stability, 0.0), 1.0)

    # ----------------------------------------
    # å¡«å……è©ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰
    # ----------------------------------------
    if filler < 0.02:
        filler_score = 1.0
    elif filler < 0.05:
        filler_score = 0.8
    else:
        filler_score = 0.65

    final = (wpm_score + silence_score + stability_score + filler_score) / 4
    return round(final, 3)

# ================================================================
# ğŸ”¹ èªéŸ³æ”¹å–„å»ºè­°ï¼ˆD åŠŸèƒ½ï¼‰
# ================================================================
def generate_speech_feedback(features):
    if not features:
        return "æœ¬æ¬¡æœªæä¾›èªéŸ³å›ç­”ï¼Œå› æ­¤ç„¡æ³•ç”¢ç”ŸèªéŸ³è¡¨é”å»ºè­°ã€‚"

    wpm = features["wpm"]
    silence = features["silence_ratio"]
    stability = features["volume_stability"]
    filler = features["filler_ratio"]

    fb = []

    # èªé€Ÿ
    if wpm < 100:
        fb.append(f"- èªé€Ÿ {wpm} WPMï¼šåæ…¢ï¼Œå¯å¤šç·´ç¿’å£èªåæ‡‰ã€‚")
    elif wpm > 180:
        fb.append(f"- èªé€Ÿ {wpm} WPMï¼šåå¿«ï¼Œå»ºè­°æ”¾æ…¢èªé€Ÿã€‚")
    else:
        fb.append(f"- èªé€Ÿ {wpm} WPMï¼šè‰¯å¥½ã€‚")

    # åœé “
    if silence > 0.25:
        fb.append(f"- åœé “æ¯”ä¾‹ {silence}ï¼šåœé “ç•¥å¤šï¼Œå»ºè­°å…ˆæ€è€ƒå†å›ç­”ã€‚")
    else:
        fb.append(f"- åœé “æ¯”ä¾‹ {silence}ï¼šè‡ªç„¶ã€‚")

    # éŸ³é‡
    if stability < 0.6:
        fb.append(f"- éŸ³é‡ç©©å®šåº¦ {stability}ï¼šéŸ³é‡èµ·ä¼æ˜é¡¯ï¼Œå¯åŠ å¼·ç©©å®šåº¦ã€‚")
    else:
        fb.append(f"- éŸ³é‡ç©©å®šåº¦ {stability}ï¼šè‰¯å¥½ã€‚")

    # å¡«å……è©
    if filler > 0.05:
        fb.append(f"- å¡«å……è©æ¯”ä¾‹ {filler}ï¼šå£é ­ç¦ªåå¤šï¼Œå»ºè­°ç·´ç¿’æ›´æµæš¢çš„å£èªã€‚")
    else:
        fb.append(f"- å¡«å……è©æ¯”ä¾‹ {filler}ï¼šæ­£å¸¸ã€‚")

    fb.append("\nå»ºè­°æ¯æ—¥éŒ„éŸ³ç·´ç¿’ 3~5 åˆ†é˜ï¼Œæœƒæ˜é¡¯æ”¹å–„èªéŸ³è¡¨é”ã€‚")

    return "\n".join(fb)


# ================================================================
# ğŸ”¹ é€é¡Œè©•åˆ†ï¼šæŠ€è¡“ / è¡¨é” / çµæ§‹ / ç›¸é—œæ€§ / è§£é¡Œèƒ½åŠ› / æ½›åŠ›
# ================================================================
def grade_single_qa(question, answer, speech_features=None):
    prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­é¢è©¦å®˜ï¼Œè«‹é‡å°å€™é¸äººçš„å›ç­”é€²è¡Œé€é¡Œè©•åˆ†ã€‚
è«‹ä¾ 6 å€‹é¢å‘è©• 1~5 åˆ†ï¼š

- technicalï¼šæŠ€è¡“æ·±åº¦
- communicationï¼šè¡¨é”æ¸…æ™°åº¦
- structureï¼šå›ç­”çµæ§‹
- relevanceï¼šæ˜¯å¦ç­”åœ¨é¡Œç›®ä¸Šï¼ˆç­”éæ‰€å•çµ¦ 1~2 åˆ†ï¼‰
- problem_solvingï¼šå•é¡Œåˆ†æèƒ½åŠ›
- growth_potentialï¼šå­¸ç¿’èˆ‡æˆé•·æ½›åŠ›

é¡Œç›®ï¼š{question}
å›ç­”ï¼š{answer}

è«‹ä»¥ JSON å›å‚³ï¼š
{{
  "technical": x,
  "communication": x,
  "structure": x,
  "relevance": x,
  "problem_solving": x,
  "growth_potential": x,
  "feedback": "ä¸€å¥è©±å›é¥‹"
}}
"""

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": prompt}],
    )

    data = json.loads(resp.choices[0].message.content)

    # â­ å°‡èªéŸ³ç‰¹å¾µç´å…¥ communication + structure
    if speech_features:
        factor = speech_feature_adjustment(speech_features)

        data["communication"] = round(data["communication"] * factor, 2)
        data["structure"] = round(data["structure"] * (0.7 + factor * 0.3), 2)

    return data


# ================================================================
# ğŸ”¹ æ•´å ´é¢è©¦ç¸½è©•
# ================================================================
def grade_interview(qa_list, job_role, resume_info=None, speech_features=None):

    per_question = []

    # --- (1) é€é¡Œè©•åˆ† ---
    for qa in qa_list:
        score = grade_single_qa(
            qa["question"],
            qa["answer"],
            speech_features=speech_features
        )
        per_question.append({
            "question": qa["question"],
            "answer": qa["answer"],
            "score": score,
            "feedback": score["feedback"]
        })

    # --- (2) è¨ˆç®—æ•´é«”å…­å‘åº¦å¹³å‡ ---
    n = len(per_question)
    overall = {
        "technical": 0,
        "communication": 0,
        "structure": 0,
        "relevance": 0,
        "problem_solving": 0,
        "growth_potential": 0,
    }

    for item in per_question:
        s = item["score"]
        for key in overall:
            overall[key] += s[key]

    for key in overall:
        overall[key] = round(overall[key] / n, 2)

    # --- (3) æ•´é«”ç¸½çµï¼ˆLLM ç”Ÿæˆï¼‰ ---
    summary_prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹é¢è©¦åˆ†æ•¸ï¼ˆ1~5ï¼‰æ’°å¯« 3~5 å¥ç¹é«”ä¸­æ–‡æ•´é«”è©•è«–ï¼š

è·ç¼ºï¼š{job_role}
åˆ†æ•¸ï¼š{overall}

ä¸è¦åˆ—é»ï¼Œåªè¦ä¸€æ®µæµæš¢è©•è«–ã€‚
"""

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": summary_prompt}]
    )

    overall["summary"] = resp.choices[0].message.content.strip()

    return {
        "overall": overall,
        "per_question": per_question
    }
