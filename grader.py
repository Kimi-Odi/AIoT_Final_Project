# ================================================================
# grader.py â€” AI è™›æ“¬é¢è©¦å®˜è©•åˆ†æ¨¡çµ„ï¼ˆå«èªéŸ³ç‰¹å¾µèª¿æ•´ + èªéŸ³æ”¹å–„å»ºè­°ï¼‰
# ================================================================

from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ================================================================
# ğŸ”¹ èªéŸ³ç‰¹å¾µèª¿æ•´ï¼ˆä½ ä¹‹å‰è¦çš„ B åŠŸèƒ½ï¼‰
# ================================================================
def speech_feature_adjustment(features):
    """
    å°‡èªéŸ³ç‰¹å¾µæ˜ å°„ç‚º 0.6ï½1.0 è©•åˆ†ä¿‚æ•¸
    å›å‚³ floatï¼Œå½±éŸ¿ communication èˆ‡ structure åˆ†æ•¸
    """
    if not features:
        return 1.0  # æ²’æœ‰èªéŸ³ â†’ ä¸èª¿æ•´

    wpm = features["wpm"]
    silence = features["silence_ratio"]
    stability = features["volume_stability"]
    filler = features["filler_ratio"]

    # -------------------------
    # WPM èªé€Ÿ
    # ç†æƒ³ï¼š100ï½180
    # -------------------------
    if wpm < 80:
        wpm_score = 0.7
    elif 80 <= wpm <= 180:
        wpm_score = 1.0
    else:
        wpm_score = 0.8

    # -------------------------
    # åœé “æ¯”ä¾‹ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰
    # -------------------------
    if silence < 0.10:
        silence_score = 1.0
    elif silence < 0.25:
        silence_score = 0.85
    else:
        silence_score = 0.65

    # -------------------------
    # éŸ³é‡ç©©å®šåº¦ï¼ˆ0~1ï¼‰
    # -------------------------
    stability_score = max(min(stability, 1.0), 0.0)

    # -------------------------
    # å¡«å……è©ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰
    # -------------------------
    if filler < 0.02:
        filler_score = 1.0
    elif filler < 0.05:
        filler_score = 0.8
    else:
        filler_score = 0.65

    final = (wpm_score + silence_score + stability_score + filler_score) / 4
    return round(final, 3)


# ================================================================
# ğŸ”¹ AI çµ¦èªéŸ³æ”¹å–„å»ºè­°ï¼ˆä½ é¸çš„ D åŠŸèƒ½ï¼‰
# ================================================================
def generate_speech_feedback(features):
    if not features:
        return "æœ¬æ¬¡æœªæä¾›èªéŸ³å›ç­”ï¼Œå› æ­¤ç„¡æ³•ç”¢ç”ŸèªéŸ³è¡¨é”å»ºè­°ã€‚"

    wpm = features["wpm"]
    silence = features["silence_ratio"]
    stability = features["volume_stability"]
    filler = features["filler_ratio"]

    feedback = []

    # èªé€Ÿ
    if wpm < 100:
        feedback.append(f"- èªé€Ÿ {wpm} WPMï¼šåæ…¢ï¼Œå¯å¤šç·´ç¿’å£èªæµæš¢åº¦ã€‚")
    elif wpm > 180:
        feedback.append(f"- èªé€Ÿ {wpm} WPMï¼šåå¿«ï¼Œå»ºè­°æ”¾æ…¢è®“èªå¥æ›´æ¸…æ™°ã€‚")
    else:
        feedback.append(f"- èªé€Ÿ {wpm} WPMï¼šè¡¨ç¾è‰¯å¥½ã€‚")

    # åœé “
    if silence > 0.25:
        feedback.append(f"- åœé “æ¯”ä¾‹ {silence}ï¼šåœé “ç•¥å¤šï¼Œå»ºè­°å…ˆçµ„ç¹”èªå¥å†å›ç­”ã€‚")
    else:
        feedback.append(f"- åœé “æ¯”ä¾‹ {silence}ï¼šè‡ªç„¶ã€è¡¨ç¾æ­£å¸¸ã€‚")

    # éŸ³é‡ç©©å®šåº¦
    if stability < 0.6:
        feedback.append(f"- éŸ³é‡ç©©å®šåº¦ {stability}ï¼šéŸ³é‡èµ·ä¼è¼ƒå¤§ï¼Œå¯ç·´ç¿’æ›´ç©©å®šçš„èªèª¿ã€‚")
    else:
        feedback.append(f"- éŸ³é‡ç©©å®šåº¦ {stability}ï¼šè‰¯å¥½ã€‚")

    # å¡«å……è©
    if filler > 0.05:
        feedback.append(f"- å¡«å……è©æ¯”ä¾‹ {filler}ï¼š'å—¯'ã€'å‘ƒ' ä½¿ç”¨åå¤šï¼Œå»ºè­°æ§åˆ¶å£é ­ç¦ªã€‚")
    else:
        feedback.append(f"- å¡«å……è©æ¯”ä¾‹ {filler}ï¼šä½¿ç”¨æ­£å¸¸ã€‚")

    feedback.append("\nå»ºè­°æ¯å¤©éŒ„éŸ³ç·´ç¿’ 5 åˆ†é˜ï¼Œå¯ä»¥æ˜é¡¯æ”¹å–„èªéŸ³è¡¨é”ã€‚")

    return "\n".join(feedback)


# ================================================================
# ğŸ”¹ å•é¡Œé€é¡Œè©•åˆ†ï¼ˆAIï¼‰
# ================================================================
def grade_single_qa(question, answer, speech_features=None):
    """
    ä½¿ç”¨ GPT åˆ†æå–®é¡Œå›ç­”â†’ å›å‚³åˆ†æ•¸ + å›é¥‹
    """
    prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­é¢è©¦å®˜ï¼Œè«‹é‡å°å€™é¸äººçš„å›ç­”é€²è¡Œé€é¡Œè©•åˆ†ã€‚
è«‹ä¾ã€ŒæŠ€è¡“ã€ã€ã€Œè¡¨é”ã€ã€ã€Œçµæ§‹ã€ã€ã€Œç›¸é—œæ€§ã€ã€ã€Œè§£é¡Œèƒ½åŠ›ã€ã€ã€Œæˆé•·æ½›åŠ›ã€å…­é …è©•åˆ†ï¼Œæ¯é … 0~5 åˆ†ã€‚

é¡Œç›®ï¼š{question}
å›ç­”ï¼š{answer}

è«‹å›å‚³ JSONï¼š
{{
  "technical": åˆ†æ•¸0~5,
  "communication": åˆ†æ•¸0~5,
  "structure": åˆ†æ•¸0~5,
  "relevance": åˆ†æ•¸0~5,
  "problem_solving": åˆ†æ•¸0~5,
  "growth_potential": åˆ†æ•¸0~5,
  "feedback": "ä¸€å¥è©±å›é¥‹"
}}
"""

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    import json
    data = json.loads(resp.choices[0].message.content)

    # â­ èªéŸ³ç‰¹å¾µèª¿æ•´ï¼šcommunication & structure
    if speech_features:
        factor = speech_feature_adjustment(speech_features)
        data["communication"] = round(data["communication"] * factor, 2)
        data["structure"] = round(data["structure"] * (0.7 + 0.3 * factor), 2)

    return data


# ================================================================
# ğŸ”¹ æ•´å ´é¢è©¦è©•åˆ†ï¼ˆæ•´åˆé€é¡Œï¼‰
# ================================================================
def grade_interview(qa_list, job_role, resume_info=None, speech_features=None):

    per_question_results = []

    # ----------- é€é¡Œåˆ†æ -----------
    for qa in qa_list:
        score = grade_single_qa(
            qa["question"], qa["answer"], speech_features=speech_features
        )
        per_question_results.append({
            "question": qa["question"],
            "answer": qa["answer"],
            "score": score,
            "feedback": score["feedback"]
        })

    # ----------- æ•´é«”å¹³å‡ -----------
    n = len(per_question_results)
    overall = {
        "technical": 0,
        "communication": 0,
        "structure": 0,
        "relevance": 0,
        "problem_solving": 0,
        "growth_potential": 0,
    }

    for item in per_question_results:
        s = item["score"]
        for k in overall:
            overall[k] += s[k]

    for k in overall:
        overall[k] = round(overall[k] / n, 2)

    # ----------- æ•´é«”è©•è«–ï¼ˆAIï¼‰-----------
    overall_prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹é¢è©¦åˆ†æ•¸ï¼Œç”Ÿæˆä¸€æ®µ 100 å­—ä»¥å…§çš„æ•´é«”è©•è«–ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚

è·ç¼ºï¼š{job_role}
é€é¡Œå¹³å‡åˆ†æ•¸å¦‚ä¸‹ï¼š
{overall}

è«‹çµ¦å‡ºç¸½çµï¼Œä¸è¦åˆ—é»ã€‚
"""

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": overall_prompt}]
    )
    overall_summary = resp.choices[0].message.content.strip()
    overall["summary"] = overall_summary

    return {
        "overall": overall,
        "per_question": per_question_results
    }
